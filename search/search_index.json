{"config":{"lang":["fr"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Legal NLP : \u00e9tat des lieux","text":"<p>Date de la version : 20/01/2023</p> <p>Cet \u00e9tat des lieux est issu de mes notes personnelles et de mes lectures. La mati\u00e8re \u00e9voluant tr\u00e8s rapidement d\u00e9sormais, je mettrai r\u00e9guli\u00e8rement \u00e0 jour cet article.</p> <p>Cela fait plusieurs ann\u00e9es que l'industrie du droit est d\u00e9fi\u00e9e par de nouvelles soci\u00e9t\u00e9s innovantes souvent regroup\u00e9es sous le terme legaltech. Des solutions tr\u00e8s int\u00e9ressantes ont \u00e9merg\u00e9 de ce bouillonnement :  </p> <ul> <li>am\u00e9lioration consid\u00e9rable des outils de recherche gr\u00e2ce \u00e0 des solutions comme Doctrine ;</li> <li>automatisation de la production documentaire et notamment des clausiers ;</li> <li>gestion \"intelligente\" des contrats ;</li> <li>extraction automatique d'informations cl\u00e9s pour analyser des documents .</li> </ul> <p>Ces solutions int\u00e9gr\u00e9es reprennent les t\u00e2ches de base que l'on peut attribuer \u00e0 des solutions de legalNLP. </p> <p>Pourtant, malgr\u00e9 ces progr\u00e8s, le coeur de l'activit\u00e9 des professionnels du droit - \u00e0 savoir le maniement de la langue et des mots - paraissa\u00eet peu sujet \u00e0 des disruptions majeures. L'arriv\u00e9e sur le march\u00e9 des Large Language Model (ci-apr\u00e8s LLM) avec leur capacit\u00e9 \u00e0 r\u00e9sumer, analyser et produire du texte pourrait d\u00e9sormais changer la donne. Au-del\u00e0 de l'int\u00e9r\u00eat du grand public pour des outils comme chatGPT, le monde du droit a tout int\u00e9r\u00eat \u00e0 s'int\u00e9resser de pr\u00e8s \u00e0 ces technologies, y compris \u00e0 travers une approche m\u00e9tier forte. </p> <p>Face \u00e0 l'engouement r\u00e9cent pour la version packag\u00e9e de GPT sous forme d'un agent conversationnel, il y a deux \u00e9coles : les enthousiastes b\u00e9ats qui ont d\u00e9j\u00e0 envahi les plateaux de t\u00e9l\u00e9vision et qui pr\u00e9tendent que le m\u00e9tier d'avocat et bien d'autres sont d\u00e9j\u00e0 pass\u00e9s aux oubliettes ; les sceptiques qui ont de solides arguments \u00e0 opposer concernant la fiabilit\u00e9 des sources et les travers de cette technologie et qui \u00e9num\u00e8rent tous les d\u00e9fauts incompatibles avec une pratique professionnelle du droit (mais \u00e9galement dans d'autres domaines comme la m\u00e9decine). </p> <p>La v\u00e9rit\u00e9, comme souvent, semble se situer entre les deux. Pour autant, je pencherai plut\u00f4t du c\u00f4t\u00e9 des enthousiastes mod\u00e9r\u00e9s, pour des solutions dans un avenir proche - horizon deux/trois ans - et j'expliquerai plus en d\u00e9tails pourquoi dans les paragraphes suivants. </p>"},{"location":"#pour-une-culture-dinterface","title":"Pour une culture d'interface","text":"<p>La diff\u00e9rence entre enthousiastes et sceptiques se fait souvent entre ceux qui utilisent chatGPT comme un produit fini, v\u00e9ritable bo\u00eete noire \u00e0 qui l'on demanderait tout et n'importe quoi et ceux qui s'\u00e9tonnent de ses r\u00e9ponses trop souvent erron\u00e9es. </p> <p>L'outil est tellement fascinant et sa capacit\u00e9 \u00e0 entretenir une conversation coh\u00e9rente - mais pas forc\u00e9ment juste -  fait que beaucoup se sont mis \u00e0 lui poser des questions tr\u00e8s pointues notamment en mati\u00e8re juridique. Etonnamment, on obtient d'assez bons r\u00e9sultats en droit am\u00e9ricain mais la r\u00e9ponse dans des domaines techniques est souvent insipide, truff\u00e9e de g\u00e9n\u00e9ralit\u00e9s voire carr\u00e9ment fausse. </p> <p>Ces errements ne doivent pas cacher une r\u00e9alit\u00e9 : ces mod\u00e8les en sont \u00e0 leurs d\u00e9buts et il y a fort \u00e0 parier qu'ils vont changer de mani\u00e8re significative le monde juridique dans les ann\u00e9es \u00e0 venir. La diff\u00e9rence se fera alors non plus entre dubitatifs ou groupies mais entre ceux qui ont une culture d'interface, c'est-\u00e0-dire \u00e0 la fois une capacit\u00e9 \u00e0 comprendre cette mati\u00e8re m\u00eame de mani\u00e8re intuitive et \u00e0 \u00e9ventuellement utiliser ces mod\u00e8les dans leur pratique, et les autres. </p> <p>Il y a plusieurs domaines ou usages pour lesquels on peut conjecturer une avenir transform\u00e9 : </p> <ul> <li>la capacit\u00e9 \u00e0 personnaliser les outils de mani\u00e8re tr\u00e8s fine avec des technologies jusque-l\u00e0 r\u00e9serv\u00e9es aux g\u00e9ants du secteur ;</li> <li>l'assistance \u00e0 la g\u00e9n\u00e9ration de documents ;</li> <li>la recherche dans des corpus documentaires \"maison\" pourrait compl\u00e9ter les outils du march\u00e9 ;</li> <li>les audits automatiques notamment dans les mati\u00e8res complexes comme la cybers\u00e9curit\u00e9, les normes en tout genre... ;</li> <li>les revues qualit\u00e9 de documents internes ;</li> <li>l'assistance juridique interne ou externe sous forme de chatbot ;</li> <li>...</li> </ul> <p>Afin de commencer notre chemin dans la culture d'interface, j'aborderai la question du traitement automatique des langues et sa place actuelle dans le domaine juridique.  On verra rapidement les limites, principales et [[#Les autres d\u00e9fis | secondaires]], de l'exercice lorsqu'on cherche \u00e0 appliquer la technique au [[#Les limites des mod\u00e8les : le raisonnement|raisonnement]] mais les r\u00e9centes avanc\u00e9es offrent des [[#Surmonter les limitations avec les LLM ? | solutions prometteuses.]]</p>"},{"location":"#le-traitement-du-langage-une-place-centrale-dans-la-pratique-du-droit","title":"Le traitement du langage : une place centrale dans la pratique du droit","text":"<p>Le traitement automatique du langage ou NLP (Natural Language Processing) a connu plusieurs \u00e9poques mais son \u00e2ge d'or a vraisemblablement commenc\u00e9 en 2017 avec les transformers dont sont issus GPT 3.x et d'autres mod\u00e8les. Ses objectifs sont rest\u00e9s les m\u00eames depuis les d\u00e9buts de la discipline dans les ann\u00e9es 50 : fournir un ensemble de techniques pour effectuer des t\u00e2ches relatives au langage habituellement effectu\u00e9es par des humains. Ces t\u00e2ches sont [[tr\u00e8s vari\u00e9es et peuvent \u00eatre plus ou moins sophistiqu\u00e9es]]. </p> <p>Pour les juristes, cette branche de l'IA joue un r\u00f4le central car elle permet d'extraire des informations \u00e0 partir de donn\u00e9es, \u00e9crites ou vocales, non structur\u00e9es. On entend par non structur\u00e9es des donn\u00e9es qui ne sont pas formatt\u00e9es \u00e0 l'origine pour \u00eatre exploit\u00e9es. Elles peuvent \u00eatre de sources tr\u00e8s vari\u00e9es : correspondance, jurisprudence, articles de doctrine, actes de proc\u00e9dure... A l'inverse,  [[les datasets pr\u00e9 formatt\u00e9s pour l'apprentissage de t\u00e2ches pr\u00e9cises]] sont un exemple de donn\u00e9es structur\u00e9es.</p>"},{"location":"#illustration-les-etapes-de-traitement-pour-lanalyse-dun-contrat","title":"Illustration : les \u00e9tapes de traitement pour l'analyse d'un contrat","text":"<p>Je reprends ici les grandes lignes de la mise en \u0153uvre du projet d'audit de documents, pr\u00e9sent\u00e9 en formation, en utilisant plusieurs briques technologiques dont la recherche s\u00e9mantique et le traitement de documents \u00e0 l'aide de LLM. </p> <p>Les \u00e9tapes simplifi\u00e9es de l'analyse d'un contrat illustrent le d\u00e9coupage n\u00e9cessaire \u00e0 une machine pour automatiser partiellement l'analyse d'un document : </p> <ol> <li>Le document doit \u00eatre pr\u00e9-trait\u00e9. Il s'agit de le nettoyer des informations non pertinentes et surtout de le d\u00e9couper en blocs tout en conservant le sens de chaque partie. Par exemple, il est possible d'extraire d'un document les phrases, \u00e9ventuellement regroup\u00e9es en paragraphes ou chapitres et dans le meilleur des cas d'essayer de conserver la structure du document initial. En effet, dans ce contexte, la hi\u00e9rarchie - le plan - a une importance s\u00e9mantique. Souvent, on utilise diff\u00e9rentes techniques dont des r\u00e9seaux de neurones ou des mod\u00e8les plus simples de machine learning .</li> <li>Il est n\u00e9cessaire d'extraire du document une premi\u00e8re s\u00e9rie d'informations comme le nom  des parties, les dates, les juridictions, les articles de loi... L\u00e0 encore, des mod\u00e8les g\u00e9n\u00e9ralistes ou entra\u00een\u00e9s sp\u00e9cifiquement peuvent \u00eatre utilis\u00e9s. </li> <li>Un classifieur peut \u00eatre appliqu\u00e9 pour identifier et extraire les clauses que l'on veut analyser : confidentialit\u00e9, non-concurrence, attributive de comp\u00e9tence, responsabilit\u00e9... </li> <li>Les extraits identifi\u00e9s peuvent \u00eatre automatiquement analys\u00e9s en fonction d'une \u00e9chelle pr\u00e9qualifiant un risque ou en utilisant des mod\u00e8les d'inf\u00e9rence (NLI). </li> <li>Toutes ces informations peuvent \u00eatre compil\u00e9es, ins\u00e9r\u00e9es dans d'autres programmes pour traitement et \u00e9valuation. </li> </ol> <p>Toutes les briques logicielles pour ces traitements existent avec une fiabilit\u00e9 plus ou moins grande qu'il faut savoir appr\u00e9hender en fonction de la criticit\u00e9 des objectifs. </p>"},{"location":"#homme-vs-machine","title":"Homme vs Machine","text":"<p>D'embl\u00e9e, on voit que l'automatisation n\u00e9cessite de mettre en \u0153uvre une pyramide de techniques pour ce qui peut prendre quelques minutes \u00e0 un humain. </p> <p>Cependant, la machine pr\u00e9sente des avantages comparatifs : </p> <ul> <li>la capacit\u00e9 \u00e0 traiter un nombre tr\u00e8s important de documents </li> <li>l'\u00e9tablissement de liens entre plusieurs sources d'informations (lois, jurisprudences, registres l\u00e9gaux, doctrine...). </li> </ul> <p>A l'inverse, l'humain excelle dans d'autres domaines :</p> <ul> <li>la compr\u00e9hension de la langue alors que la machine repose sur des mod\u00e8les purement math\u00e9matiques ; </li> <li>l'appr\u00e9hension d'un probl\u00e8me \u00e0 partir d'un faible nombre d'exemples ; </li> <li>l'application d'un raisonnement juridique qui n'est pas accessible \u00e0 la machine sauf \u00e0 utiliser des techniques commes les ontologies ([[ontologie_knowledge_graph]]) ou \u00e0 d\u00e9composer les prompts en Chain of Thought  m\u00e9tiers.</li> </ul>"},{"location":"#les-limites-des-modeles-le-raisonnement","title":"Les limites des mod\u00e8les : le raisonnement","text":"<p>Pour illustrer la position du probl\u00e8me, imaginons que l'on veuille pr\u00e9dire l'issue d'un litige. Cette activit\u00e9, que certains nomment justice pr\u00e9dictive ou algorithmis\u00e9e, peut faire l'objet de plusieurs approches techniques. </p>"},{"location":"#lextraction-de-regularites-statistiques","title":"L'extraction de r\u00e9gularit\u00e9s statistiques","text":"<p>Ici, la premi\u00e8re \u00e9tape est extractive : il s'agit d'utiliser des techniques permettant d'isoler les diff\u00e9rents \u00e9l\u00e9ments d'une d\u00e9cision comme nous l'avons vu pour les contrats. Le mod\u00e8le de NLP doit pouvoir identifier les parties, les textes appliqu\u00e9s, les faits et la d\u00e9cision finale. Si l'on admet que cette t\u00e2che est correctement effectu\u00e9e, on pourra alors faire tourner d'autres mod\u00e8les pour capturer des sch\u00e9mas statistiques qui permettront de pr\u00e9dire l'issue d'un litige en fonction de plusieurs \u00e9l\u00e9ments comme la nature du litige, les faits, la juridiction... L'issue du litige \u00e9tant ici une classification discr\u00e8te (perd/gagne) ou continue comme le montant d'une indemnisation, d'une pension alimentaire ou une prestation compensatoire. </p> <p>Cette approche admet plusieurs limites : </p> <ul> <li>les techniques de NLP ne peuvent identifier \u00e0 elles seules les informations pertinentes. Dans ce cas, un homme de l'art est n\u00e9cessaire pour identifier les \u00e9l\u00e9ments cl\u00e9s et invariants d'un litige ;</li> <li>cette approche est plus adapt\u00e9e au syst\u00e8me de common law que dans les pays de droit civil ;</li> <li>la limitation majeure provient, selon moi, de l'incapacit\u00e9 \u00e0 obtenir un raisonnement qui prenne en compte les faits, leur qualification et l'application de la r\u00e8gle de droit.</li> </ul>"},{"location":"#les-difficultes-de-limplementation-dun-raisonnement-juridique","title":"Les difficult\u00e9s de l'impl\u00e9mentation d'un raisonnement juridique","text":"<p>Pour r\u00e9ellement arriver \u00e0 raisonner, il faudrait que nos techniques de NLP soient capables d'orchestrer les connaissances et de leur appliquer des m\u00e9canismes d'inf\u00e9rence.</p> <p>Les [[ontologie_knowledge_graph |ontologies et/ou les graphs de connaissance ]]pr\u00e9sentent des avantages certains pour appr\u00e9hender le raisonnement juridique. Ci-dessous, une approche du RGPD que j'ai impl\u00e9ment\u00e9e dans une base de donn\u00e9es sp\u00e9cialis\u00e9e. La connaissance est repr\u00e9sent\u00e9e sous forme de triplets sujet-verbe-objet. </p> <p>Ainsi le RGPD poss\u00e8de des concepts qui se d\u00e9clinent en entit\u00e9s, en droit des personnes, en donn\u00e9es, etc. Chaque sous-concept est reli\u00e9 aux autres par un lien hi\u00e9rarchique, une relation d'implication pour \u00e9voquer la transversalit\u00e9, une r\u00e9f\u00e9rence \u00e0 sa d\u00e9finition pour relier les textes ou la jurisprudence au concept. </p> <p>Cette structuration de l'information permet une manipulation tr\u00e8s puissante. Ainsi, on peut extraire facilement les liens fonctionnels entre les activit\u00e9s de traitement et les entit\u00e9s concern\u00e9es. L'ensemble fait sens et permet d'inf\u00e9rer des obligations, des droits, des activit\u00e9s prohib\u00e9es, etc. Seulement, ce graph n\u00e9cessite une intervention humaine en amont et sa construction automatique \u00e0 partir des techniques du NLP est impossible (malgr\u00e9 quelques promesses non tenues de fournisseurs de solutions). </p> <p>Il existe de nombreux tutoriels qui d\u00e9taillent comment cr\u00e9er des ontologies \u00e0 partir de bases de donn\u00e9es de films par exemple. Dans ce cadre, le but est d'extraire les liens entre le sujet (un acteur, un producteur, un r\u00e9alisteur) et les objets (les films). Le NLP utilise plusieurs techniques pour y arriver : Part Of Speech, analyse des d\u00e9pendances, Name Entity Recognition, etc.</p> <p>Mais en mati\u00e8re juridique, la complexit\u00e9 du graph \u00e0 construire interdit de consid\u00e9rer ce proc\u00e9d\u00e9 automatique comme fiable. </p> <p>Cette limitation ne peut pas \u00eatre surmont\u00e9e aujourd'hui y compris par les LLM. Pour autant, cette approche peut apporter des avanc\u00e9es majeures au domaine du traitement automatique du droit. J'y reviendrai. </p>"},{"location":"#surmonter-les-limitations-avec-les-llm","title":"Surmonter les limitations avec les LLM ?","text":"<p>Comme nous l'avons mentionn\u00e9, les LLM apportent des avanc\u00e9es importantes qui peuvent b\u00e9n\u00e9ficier au domaine du droit : </p>"},{"location":"#lapprentissage-avec-pas-ou-peu-dexemples-zero-shot-few-shots-learning","title":"L'apprentissage avec pas ou peu d'exemples (zero shot &amp; few shots learning)","text":"<p>Cette caract\u00e9ristique, sur laquelle je reviens en d\u00e9tails dans [[LLM_art_prompting |l'art du prompting]] permet au mod\u00e8le d'\u00eatre utilis\u00e9 pour des t\u00e2ches sp\u00e9cifiques en lui fournissant aucun ou tr\u00e8s peu d'exemples.  Elle repr\u00e9sente un atout car elle  vient pallier la raret\u00e9 et le co\u00fbt de constitution des donn\u00e9es lab\u00e9lis\u00e9es disponibles en droit fran\u00e7ais.  </p> <p>Par exemple, le prompt  \"Extrait les textes de lois et les entit\u00e9s nomm\u00e9s du texte suivant au format csv.\" appliqu\u00e9 \u00e0 l'arr\u00eat de la chambre criminelle du 29 novembre 2022 donne le r\u00e9sultat suivant : </p> <p></p> <p>Bien entendu, ces r\u00e9sultats sont \u00e0 affiner et \u00e0 \u00e9valuer. Cependant, on aper\u00e7oit le caract\u00e8re remarquable de GPT (davinci-003) \u00e0 reconna\u00eetre des entit\u00e9s l\u00e0 o\u00f9 il fallait entra\u00eener au pr\u00e9alable un mod\u00e8le avec plusieurs milliers d'exemples. C'est une des illustrations de la puissance du zero shot learning. </p> <p>Il serait int\u00e9ressant de comparer les r\u00e9sultats au tryptique titrages, r\u00e9sum\u00e9s, textes appliqu\u00e9s fourni par le Bulletin. </p> <p>En revanche, cette habilet\u00e9 seule ne permet pas de raisonner mais de se passer d'un long et co\u00fbteux apprentissage. Si ces mod\u00e8les peuvent faire \u00e9conomiser du texte, ont-ils l'aptitude \u00e0 b\u00e2tir un sch\u00e9ma de connaissance ? </p>"},{"location":"#lelaboration-automatique-dontologies","title":"L'\u00e9laboration automatique d'ontologies","text":"<p>Si l'on poursuit notre id\u00e9e, notre r\u00e9seau pr\u00e9-entra\u00een\u00e9 pourrait \u00eatre capable d'extraire des structures qui pourraient ensuite \u00eatre utilis\u00e9es dans des graphs de connaissance. Cette exp\u00e9rience a \u00e9t\u00e9 men\u00e9e sur des d\u00e9cisions de justice am\u00e9ricaine avec le format json-ld. Bien qu'imparfait, GPT a pu g\u00e9n\u00e9rer des fichiers dans un format structur\u00e9 \u00e0 partir des opinions de la Cour Supr\u00e8me des Etats-Unis. C'est un premier pas modeste vers une capacit\u00e9 \u00e0 raisonner. Le sujet est \u00e0 creuser notamment en droit fran\u00e7ais. </p> <p>Mais le NLP doit r\u00e9pondre \u00e0 d'autres d\u00e9fis compl\u00e9mentaires pour arriver \u00e0 sa pleine maturit\u00e9 dans le domaine juridique. </p>"},{"location":"#les-autres-defis","title":"Les autres d\u00e9fis","text":""},{"location":"#la-diversite-des-documents-juridiques-constitue-un-premier-ecueil","title":"La diversit\u00e9 des documents juridiques constitue un premier \u00e9cueil","text":"<p>Les documents juridiques prennent des formes vari\u00e9es et n'ob\u00e9issent pas \u00e0 des mod\u00e8les pr\u00e9formatt\u00e9s.  Ce formalisme extensif engendre des probl\u00e8mes sp\u00e9cifiques lorsqu'il s'agit d'extraire l'information d'un document. </p>"},{"location":"#lidentification-de-la-structure-documentaire","title":"L'identification de la structure documentaire","text":"<p>Certes, la mati\u00e8re juridique conduit \u00e0 produire du contenu plus structur\u00e9 que dans d'autres domaines mais le formalisme peut \u00eatre plus ou moins strict. </p> <p>Par exemple, il n'existe pas de structure r\u00e9ellement unifi\u00e9e respect\u00e9e par les d\u00e9cisions de justice m\u00eame si l'on peut s'appuyer sur des plans de classement parfois tr\u00e8s performant. Le blog d'Emmanuel Barthe en fournit un int\u00e9ressant \u00e9tat des lieux. </p> <p>Dans la documentation produite par les avocats, il existe \u00e9galement une grande vari\u00e9t\u00e9 de structures. La r\u00e9p\u00e9tition de sch\u00e9mas types comme en mati\u00e8re contractuelle permet d'entra\u00eener des  mod\u00e8les de machine learning classiques pour extraire la structure hi\u00e9rarchique et les unit\u00e9s de texte (paragraphes) pour effectuer des traitements en aval. </p>"},{"location":"#quel-niveau-de-granularite","title":"Quel niveau de granularit\u00e9 ?","text":"<p>Un probl\u00e8me courant en NLP est la taille des donn\u00e9es \u00e0 traiter. L'architecture [[Les Transformers|des transformers]] conduit \u00e0 une limitation des s\u00e9quences en entr\u00e9e qui peuvent \u00eatre trait\u00e9es en m\u00eame temps. Cette limitation porte sur le nombre de tokens (un token \u00e9gal \u00e0 peu pr\u00e8s 0,75 mot ). </p> <p>La plupart des documents juridiques d\u00e9passent largement la fen\u00eatre, comprise entre 500 et 4000 tokens, utilis\u00e9e par ces mod\u00e8les. </p> <p>Cette caract\u00e9ristique contraint \u00e0 segmenter le texte en plusieurs morceaux avec une perte in\u00e9vitable d'informations. Une des solutions, illustr\u00e9e dans la mise en pratique sur le moteur de recherche s\u00e9mantique, consiste \u00e0 superposer partiellement les segments mais cette solution n'est pas toujours satisfaisante. En effet, le d\u00e9coupage arbitraire am\u00e8ne parfois \u00e0 d\u00e9grader l'analyse du sens. </p>"},{"location":"#la-penurie-de-jeux-de-donnees","title":"La p\u00e9nurie de jeux de donn\u00e9es","text":"<p>Malgr\u00e9 l'aptitude \u00e0 apprendre \u00e0 partir de peu d'exemples, il est souvent n\u00e9cessaire d'alimenter les mod\u00e8les en donn\u00e9es d'apprentissage. </p> <p>Les progr\u00e8s r\u00e9cents de l'open data en mati\u00e8re judiciaire sont tr\u00e8s encourageants mais le droit fran\u00e7ais manque cruellement de datasets structur\u00e9s \u00e0 la fois pour l'apprentissage et pour \u00e9tablir des benchmarks. </p> <p>Je r\u00e9f\u00e9rence dans l'article consacr\u00e9 aux jeux de donn\u00e9es  (dataset), ceux qui sont accessibles publiquement en droit fran\u00e7ais ou francophone (droit belge, suisse principalement ). Si vous avez connaissance d'autres jeux de donn\u00e9es, n'h\u00e9sitez pas \u00e0 m'\u00e9crire. </p> <p>En conclusion, il est impossible, aujourd'hui, pour le juriste d\u2019avoir les connaissances techniques d\u2019hier pour comprendre un monde o\u00f9 le num\u00e9rique est inextricablement li\u00e9 au droit.</p> <p>La culture d\u2019interface doit permettre \u00e0 nos professions d\u2019appr\u00e9hender facilement les enjeux souvent cach\u00e9s dans les univers comme l\u2019intelligence artificielle.</p>"},{"location":"a_propos/","title":"A propos","text":"<p>Ce site  regroupe mes notes depuis 2019 concernant le Traitement automatique des langues (Natural Language Processing) appliqu\u00e9 au domaine juridique. </p> <p>J'ai pens\u00e9 qu'elles pourraient \u00eatre utiles compte tenu du  r\u00e9cent engouement pour les Large Language Model et de l'effervescence qui entoure d\u00e9sormais la mati\u00e8re. </p> <p>Il est un compl\u00e9ment utile aux formations o\u00f9 toutes ces notions sont d\u00e9roul\u00e9es de mani\u00e8re plus compl\u00e9te et font l'objet de mises en \u0153uvre pratiques. </p> <p>Voici le d\u00e9tail de ce que vous allez y trouver : </p> <ul> <li>Les notions essentielles regroupent ce qu'il faut conna\u00eetre pour acqu\u00e9rir une appr\u00e9hesion des mod\u00e8les de langage. Ce sont des articles courts. J'y ai \u00e9galement r\u00e9f\u00e9renc\u00e9 quelques liens pour aller plus loin. </li> <li>Les ressources d\u00e9taillent un ensemble de liens utiles, de librairie et des papiers de recherche dans le domaine du legal NLP. </li> <li>Le r\u00e9pertoire enjeux et r\u00e9gulation pr\u00e9sente une liste de r\u00e9flexions/synth\u00e8ses sur les enjeux li\u00e9s \u00e0 la mati\u00e8re au regard notamment de la directive IA mais \u00e9galement la s\u00e9curit\u00e9, les mod\u00e8les de confiance, l'explicabilit\u00e9... </li> <li>Enfin, les projets d\u00e9taillent des mises en \u0153uvre concr\u00e8tes \u00e0 partir de papiers de recherche, de framework comme LangChain ...</li> </ul> <p>Le contenu de ce site n'est \u00e9videmment pas exhaustif et beaucoup d'am\u00e9liorations peuvent y \u00eatre apport\u00e9es. N'h\u00e9sitez pas \u00e0 me faire part de vos critiques, de relever des erreurs ou des impr\u00e9cisions concernant le contenu. </p>"},{"location":"Enjeux_%26_R%C3%A9gulation/fiabiliiser_les_LargeLanguageModels/","title":"Fiabiliser les LLM : quelques pistes","text":"<p>Le succ\u00e8s de ChatGPT est d\u00fb pour beaucoup \u00e0 sa capacit\u00e9 presque mim\u00e9tique de dialoguer. En greffant \u00e0 GPT une m\u00e9moire des \u00e9changes et une am\u00e9lioration des r\u00e9ponses gr\u00e2ce au feedback humain, les \u00e9quipes d'openAI ont cr\u00e9\u00e9 un agent conversationnel tellement bluffant que son utilisation s'est r\u00e9pandue comme une tra\u00een\u00e9e de poudre.  Sa connaissance extensive dans presque tous les domaines lui conf\u00e8re un pouvoir de quasi-oracle r\u00e9pondant \u00e0 toutes les questions que nous, pauvres humains, pouvons lui poser. </p> <p>Cet enthousiasme a fait oublier \u00e0 certains la nature m\u00eame de GPT et les cons\u00e9quences sur ses r\u00e9ponses. Il ne s'agit 'que' d'un mod\u00e8le de langage, c'est-\u00e0-dire une machine \u00e0 produire des mots selon une approche probabiliste, d'o\u00f9 le diminutif de stochastic parrot que certains lui ont afffubl\u00e9. La nature profonde de GPT a deux cons\u00e9quences : </p> <ul> <li>il a une \"connaissance\" param\u00e9trique d'un monde fig\u00e9 ;</li> <li>le mod\u00e8le peut halluciner c'est-\u00e0-dire fournir des r\u00e9ponses inexactes factuellement ou de pur non-sens. </li> </ul> <p>La connaissance fig\u00e9e est due au fait que ce type de mod\u00e8le est extr\u00e9mement co\u00fbteux \u00e0 entra\u00eener et qu'il n'est pas possible de le mettre \u00e0 jour en temps r\u00e9el. </p> <p>L'hallucination provient du fait que GPT ne contient pas une base de donn\u00e9es interrne de ses sources. Il est constitu\u00e9 de poids (param\u00e8tres) appris lors de la phase d'entra\u00eenement qui lui permettent de g\u00e9n\u00e9rer un mot (appel\u00e9 token) en fonction de la s\u00e9quence des mots qui lui sont fournis. Rien de plus. La grande masse des donn\u00e9es d'apprentissage ne reste pas dans le mod\u00e8le. Il peut donc produire une sortie qui n'est pas fiable sur le plan de la v\u00e9rit\u00e9 et m\u00eame incoh\u00e9rente pour notre bon sens d'\u00eatre humain. Les deux travers \u00e9tant cumulables. </p> <p>Pis, sa mani\u00e8re de s'exprimer avec confiance ajoute une couche dans la duperie, si j'ose dire. Comment ne pas croire un syst\u00e8me qui conna\u00eet tout ou presque, de la th\u00e9orie musicale en passant par la m\u00e9decine et la physique quantique. Une aussi grande connaissance, affirm\u00e9e avec aplomb, ne saurait mentir. Non seulement, il ment mais en plus il ne le sait pas ! </p> <p>Cet inconv\u00e9nient majeur a \u00e9t\u00e9 \u00e9galement gomm\u00e9 par la guerre r\u00e9cente que se livrent Google et Microsoft concernant la recherche am\u00e9lior\u00e9e par ces mod\u00e8les de langage. Ce n'est pas pour rien que Google n'avait pas int\u00e9gr\u00e9 dans la version grand public son mod\u00e8le maison (LaMDA). </p> <p>Pourtant, il existe des parades pour se pr\u00e9munir, partiellement, de ces faiblesses. L'avantage de ces approches est de pouvoir b\u00e9n\u00e9ficier du meilleur des deux mondes : la capacit\u00e9 \u00e0 manipuler la langue associ\u00e9e au LLM et le pouvoir de rendre l'information fiable en tra\u00e7ant les sources. </p> <p>Pour y parvenir, il existe trois techniques : la premi\u00e8re, le fine tuning, consiste \u00e0 adapter le LLM avec des donn\u00e9es sp\u00e9cifiques produites et ma\u00eetris\u00e9es. La deui\u00e8me consiste \u00e0 piloter le LLM, via le prompting, pour restreindre le contexte de sa r\u00e9ponse. Enfin, la derni\u00e8re est de mixer une approche de base de connaissances avec une capacit\u00e9 de recherche dont les r\u00e9ponses seront trait\u00e9es par le LLM dans la phase finale. </p>"},{"location":"Enjeux_%26_R%C3%A9gulation/fiabiliiser_les_LargeLanguageModels/#le-fine-tuning","title":"Le fine tuning","text":"<p>Il ne faut pas oublier que la connaissance pr\u00e9sente dans le LLM n'est pas connue et, par cons\u00e9quent, doit \u00eatre consid\u00e9r\u00e9e comme non fiable dans la plupart des contextes m\u00e9tiers. Les mod\u00e8les de langage pr\u00e9 entra\u00een\u00e9s sont de v\u00e9ritables bo\u00eetes noires dont l'explicabilit\u00e9 des sortes n'est pas possible.</p> <p>Le fine tuning consiste \u00e0 adapter le mod\u00e8le fig\u00e9 \u00e0 des t\u00e2ches sp\u00e9cifiques. Les modalit\u00e9s de l'adaptation peuvent \u00eatre diverses. Par exemple, chatGPT est issu du fine tuning de GPT.</p> <p>Une des mani\u00e8res d'adapter un mod\u00e8le pr\u00e9 entra\u00een\u00e9 est d'ajouter une couche de donn\u00e9es d'apprentissage. On adapte ainsi un mod\u00e8le pr\u00e9-entra\u00een\u00e9 \u00e0 un domaine sp\u00e9cifique. Cette approche est tr\u00e8s utilis\u00e9e car elle permet de se passer de la phase d'entra\u00eenement tr\u00e8s co\u00fbteuse qui fait la force des LLM. </p> <pre><code>flowchart TD \n    direction TB\n    A[Donn\u00e9es sp\u00e9cifiques] --&gt; B[LLM pr\u00e9 entra\u00een\u00e9] \n    B --&gt; C[Couche d'Adaptation]\n    C --&gt; D(Sorties adapt\u00e9es)\n</code></pre> <p>Le fine tuning, dans une approche de fiabilisation, des r\u00e9ponses n'est pas la panac\u00e9e, et ce pour plusieurs raisons : </p> <ul> <li>l'ensemble obtenu reste fig\u00e9 au sens o\u00f9 il faut un r\u00e9 entra\u00eenement - m\u00eame minimal - pour mettre \u00e0 jour les connaissances ;</li> <li>les donn\u00e9es d'adaptation p\u00e8sent un poids infime face aux donn\u00e9es d'apprentissage initial et donc n'ont que peu de poids dans le rendu final. </li> </ul> <p>Pour pallier ces inconv\u00e9nients, une autre approche est d'utiliser le prompting pour limiter la r\u00e9ponse du LLM \u00e0 un contexte particulier. </p>"},{"location":"Enjeux_%26_R%C3%A9gulation/fiabiliiser_les_LargeLanguageModels/#le-prompting-contraignant-et-linjection-de-contexte","title":"Le prompting contraignant et l'injection de contexte","text":"<p>Une solution simple consiste \u00e0 contraindre le mod\u00e8le par une instruction de type \"Fourni une r\u00e9ponse la plus fiable possible et, si tu n'es pas s\u00fbr de ta r\u00e9ponse, r\u00e9ponds \"D\u00e9sol\u00e9, je ne sais pas\". Ce simple prompt permet de limiter le mod\u00e8le dans la confiance qu'il apporte \u00e0 la r\u00e9ponse.  En principe... </p> <p>Une mani\u00e8re plus efficiente est, selon moi, d'ajouter un contexte au prompt. Le contexte consiste \u00e0 limiter la r\u00e9ponse au prompt par le LLM avec un \u00e9lement de contenu particulier qui va restreindre sa completion comme l'illustre l'exemple suivant: </p> <p> </p> <p>Cet angle semble plus prometteur et plus s\u00fbr que la premi\u00e8re approche plus g\u00e9n\u00e9rale. Mais cela ne r\u00e9pond pas \u00e0 la question de l'actualisation des connaissances. Cette probl\u00e9matique fait l'objet depuis plusieurs ann\u00e9es de travaux de recherche. Une des solutions consiste \u00e0 mixer les LLM avec des outils de recherche s\u00e9mantique plus \"traditionnelles\" ssets/img/prompt_gpt_ccass1.png)</p>"},{"location":"Enjeux_%26_R%C3%A9gulation/fiabiliiser_les_LargeLanguageModels/#lapproche-in-context-ralm-retrieval-augmented-language-model","title":"L'approche in-context RALM (Retrieval Augmented Language Model)","text":"<p>Celle-ci vise \u00e0 combiner trois couches : </p> <ul> <li>la premi\u00e8re traite la requ\u00eate qui est transform\u00e9e en vecteur (encoder) ;</li> <li>la requ\u00eate est compar\u00e9e \u00e0 une base de connaissances stock\u00e9e g\u00e9n\u00e9ralement sous forme de vecteurs mais une approche plus traditionnelle (statistique) est possible ; </li> <li>les documents obtenus sont ensuite re-trait\u00e9s via un LLM pour r\u00e9pondre \u00e0 une question, fournir un r\u00e9sum\u00e9 \u00e0 partir de plusieurs documents, etc. </li> </ul> <pre><code>flowchart TD\nsubgraph one[Retriever]\n    direction TB\n    A[\"Qu'est ce qu'une convention secr\u00e8te ?\"] -- Encoder --&gt;B[(Vector Database)]\nend\none -- Documents similaires --&gt; two\nsubgraph two[Augmented Language Model]\n    direction TB\n    D[LLM]--In Context Prompt--&gt;E[Completion] \n\nend\ndirection RL\ntwo --&gt; F(R\u00e9ponses finales)\n\n\n</code></pre> <p>Ce mod\u00e8le pr\u00e9sente plusieurs avantages : </p> <ul> <li>l'information peut \u00eatre mise \u00e0 jour en temps r\u00e9el car la base de connaissances est dynamique ; </li> <li>l'information est fiable car ma\u00eetris\u00e9e par le ma\u00eetre d'\u0153uvre ;</li> <li>les r\u00e9sultats utilisent la puissance des LLM pour effectuer des t\u00e2ches comme les questions/r\u00e9ponses ou des r\u00e9sum\u00e9s. </li> </ul> <p>Parmi les projets en cours, deux abordent cette question sous l'angle de la recherche s\u00e9mantique et de la capacit\u00e9 \u00e0 retravailler les r\u00e9sultats obtenus en utilisant les LLM. </p> <p>Liens utiles : </p> <p>https://www.topbots.com/overcoming-the-limitations-of-large-language-models/ https://bdtechtalks.com/2023/01/30/ai21labs-llms-ralm/ https://towardsdatascience.com/chatgpt-insists-i-am-dead-and-the-problem-with-language-models-db5a36c22f11</p>"},{"location":"Notions_Essentielles/0_Les%20principales%20t%C3%A2ches%20du%20legal%20NLP/","title":"Les principales t\u00e2ches du Legal NLP","text":"<p>Il faut distinguer les t\u00e2ches g\u00e9n\u00e9ralistes de celles qui sont sp\u00e9cifiques \u00e0 notre domaine, le legal NLP. Les t\u00e2ches g\u00e9n\u00e9ralistes sont extr\u00eamement nombreuses et la distinction entre elles est parfois t\u00e9nue.</p> <p>Cette image qui d\u00e9crit les fonctionnalit\u00e9s de la suite logicielle \"legal NLP\" montre quelques-unes des fonctionnalit\u00e9s cl\u00e9s du legal NLP :</p> <p> Source : (Legal NLP - John Snow Lab https://www.johnsnowlabs.com/legal-nlp/)</p> <p>En mati\u00e8re de legal NLP, les traitements sont g\u00e9n\u00e9ralement :</p> <ul> <li>pr\u00e9dir l'issue d'une d\u00e9cision de justice (Legal Justice Prediction) \u00e0 partir des faits, de la proc\u00e9dure, de la mati\u00e8re, des parties, etc. ;</li> <li>extraire des entit\u00e9s nomm\u00e9es comme la date de la d\u00e9cision, le nom des parties, le nom de la juridiction, les textes cit\u00e9s, etc. ;</li> <li>\u00e9tablir des liens entre les entit\u00e9s : raccorder un contrat aux textes de loi auxquels il se r\u00e9f\u00e8re par exemple ou faire un lien avec l'identit\u00e9 des parties ;</li> <li>classifier du texte : par exemple, savoir si une clause est conforme ou non au droit de la consommation ;</li> <li>extraire des morceaux d'un texte : par exemple identifier des clauses particuli\u00e8res dans un contrat ;</li> <li>r\u00e9pondre \u00e0 des questions juridiques pour cr\u00e9er un assistant conversationnel ;</li> <li>automatiser des traitements \u00e0 des fins d'anonymisation ;</li> <li>r\u00e9sumer des textes longs pour cr\u00e9er des abstracts de d\u00e9cision par exemple ;</li> <li>\"raisonner\" par inf\u00e9rence, c'est-\u00e0-dire d\u00e9terminer si une phrase est la suite logique, en contradiction ou neutre par rapport \u00e0 une autre (pr\u00e9misse) ;</li> <li>comparer la similarit\u00e9 de textes notamment des d\u00e9cisions de justice ; </li> <li>...</li> </ul>"},{"location":"Notions_Essentielles/10_modeles_pre_entraines/","title":"L'utilisation des mod\u00e8les pr\u00e9-entra\u00een\u00e9s","text":"<p>En mati\u00e8re de traitement du langage, il est extr\u00e9mement fr\u00e9quent d'avoir recours \u00e0 un mod\u00e8le d\u00e9j\u00e0 existant que l'on r\u00e9-entra\u00eene sur des t\u00e2ches sp\u00e9cifiques. </p> <p>Ce ph\u00e9nom\u00e8ne est d'abord apparu avec les images au d\u00e9but des ann\u00e9es 2010 puis, \u00e0 partir de 2018 et la sortie du mod\u00e8le BERT, il s'est invit\u00e9 dans le monde du NLP. </p> <p>Auparavant, les t\u00e2ches \u00e9taient silot\u00e9es ainsi que les \u00e9quipes de recherche. On distinguait classiquement plusieurs cat\u00e9gories :</p> <ul> <li>la classification d'une phrase ou d'un document (spam, fake news, critique, ...)</li> <li>ll labelisation de s\u00e9quences (pr\u00e9voir la nature grammatical d'un mot, reconna\u00eetre des entit\u00e9s)</li> <li>l'\u00e9tablissement des relations entre les s\u00e9quences (sujet, verbe, objet)</li> <li>la g\u00e9n\u00e9ration de texte : traduire ou r\u00e9sum\u00e9 par exemple. </li> </ul> <p>A chacune de ces t\u00e2ches, on associait un mod\u00e8le, des donn\u00e9es et un entra\u00eenement. D\u00e9sormais, l'\u00e9tat de l'art est d'utilis\u00e9 un premier mod\u00e8le comme socle de connaissance puis d'entra\u00eener des couches de neurones sp\u00e9cifiques associ\u00e9es \u00e0 des donn\u00e9es nouvelles en vue de sp\u00e9cialiser l'ensemble. </p> <p>Ce nouveau paradigme a des implications qui vont bien au del\u00e0 des aspects purement technique de la discipline. Avant de d\u00e9crire sommairement la traduction technique et concr\u00e8te pour les praticiens,  il faut revenir sur l'origine de ce ph\u00e9nom\u00e8ne. </p>"},{"location":"Notions_Essentielles/10_modeles_pre_entraines/#des-modeles-pre-entraines-aux-foundation-models","title":"Des mod\u00e8les pr\u00e9 entra\u00een\u00e9s aux foundation models","text":""},{"location":"Notions_Essentielles/10_modeles_pre_entraines/#les-conditions-de-lemergence","title":"Les conditions de l'\u00e9mergence","text":"<p>L'\u00e9mergence de cette pratique \u00e9pouse les m\u00eames conditions que le succ\u00e8s fulgurant du deep learning  ces derni\u00e8res ann\u00e9es : </p> <ul> <li>augmentation de la puissance machine gr\u00e2ce au GPU; </li> <li>\u00e9laboration de nouvelle architecture plus facilement entra\u00eenable (Transformers); </li> <li>explosition du nombre de donn\u00e9es disponibles. </li> </ul> <p>C'est ce dernier ph\u00e9nom\u00e8ne qui a \u00e9t\u00e9 le plus massif dans le secteur du langage. Dans le secteur, il est fait recours massivement \u00e0 l'apprentissage auto-supervis\u00e9  (self supervised learning). Par exemple, un mod\u00e8le qui vise \u00e0 apprendre \u00e0 g\u00e9n\u00e9rer des mots a uniquement besoin de phrases en entr\u00e9e. Le label est constitu\u00e9 par le mot qui est masqu\u00e9 et qui doit \u00eatre d\u00e9couvert par le mod\u00e8le.  </p> <p>Cet aspect est essentiel car il a permis de recourir \u00e0 une volum\u00e9trie massive de donn\u00e9es \u00e0 moindre co\u00fbt car sans intervention humaine. Cette mani\u00e8re d'entra\u00eener les mod\u00e8les est l'\u00e9tat de l'art en NLP depuis 2019. </p> <p>Le monde de la recherche a rapidement \u00e9tabli que l'alliance de ces mod\u00e8les sur \u00e9tag\u00e8re associ\u00e9s \u00e0 des couches sp\u00e9cialis\u00e9es, dans le cadre d'une approche dite de  transfer learning (1976, Bozinovski) ,\u00e9taient bien plus performante que l'\u00e9tat de l'art ant\u00e9rieur bas\u00e9 sur des architecttures sp\u00e9cialis\u00e9es. </p> <p>D\u00e8s lors, une course effr\u00e9n\u00e9e  dans la cr\u00e9ation de mod\u00e8les toujours plus massif aussi bien en terme de volumes de donn\u00e9es d'entra\u00eenement qu'en nombre de param\u00e8tres comme en t\u00e9moigne ce graphique : </p> <p> Trend of sizes of state-of-the-art NLP models over time on a logarithmic scale Source: Microsoft Research blog post on 11th Oct 2021</p>"},{"location":"Notions_Essentielles/10_modeles_pre_entraines/#la-formalisation-du-concept-de-modele-socle-ou-foundation-model","title":"La formalisation du concept de mod\u00e8le socle ou foundation model","text":"<p>N\u00e9e de la pratique, les mod\u00e8les pr\u00e9 entra\u00een\u00e9s ont rapidement \u00e9t\u00e9 renomm\u00e9s foundation model ou mod\u00e8le socle pour signfier \u00e0 la fois leur place dans l'architecture finale mais \u00e9galement les enjeux fondamentaux en jeu bien au del\u00e0 du domaine du machine learning. </p> <p>Je ferai une \u00e9tude plus d\u00e9taill\u00e9 sur les implications, notamment juridique, de cette pratique de l'industrie. </p> <p>Pour l'heure, d'autres aspects commandent les modalit\u00e9s pratiques d'utilisation avec ses avantages et ses risques. </p>"},{"location":"Notions_Essentielles/10_modeles_pre_entraines/#lutilisation-des-foundations-models","title":"L'utilisation des foundations models","text":"<p>La production de ces mod\u00e8les massifs n'est accessible qu'\u00e0 quelques entreprises sur le plan mondial compte tenu des ressources et des comp\u00e9tences \u00e0 mobiliser. </p> <p>Cet constat a provoqu\u00e9 \u00e9galement un arr\u00eat partiel des pratiques permettant d'\u00e9tudier et de reproduire les mod\u00e8les en laboratoire. A cela, il faut ajouter, comment mentionn\u00e9 dans la partie sur les datasets, la gestion d'une volum\u00e9trie gigantesque et l'absence de transparence qui caract\u00e9rise souvent l'industrie priv\u00e9e dans ce domaine. </p> <p>Dans ce panaroma pessimiste, il faut mentionner plusieurs initiatives visant \u00e0 contre- carrer cette \u00e9volution comme Eleuther.ai ou BLOOM \u00e0 l'initiative de la soci\u00e9t\u00e9 HuggingFace et qui a re\u00e7u des financements publics fran\u00e7ais. </p> <p>Cet \u00e9tat de fait ne se limite pas \u00e0 la production mais influe \u00e9galement l'utilisation car les conditions techniques et le co\u00fbt \u00e9conomique associ\u00e9 pour mettre en oeuvre les inf\u00e9rences est l\u00e0 encore d\u00e9m\u00e9sur\u00e9. </p>"},{"location":"Notions_Essentielles/10_modeles_pre_entraines/#panorama-des-conditions-dutilisation","title":"Panorama des conditions d'utilisation","text":"<p>De mani\u00e8re simplifi\u00e9e le sch\u00e9ma d'utilisation est le suivant : </p> <pre><code>flowchart BT\n\nA[Donn\u00e9es Massives] -- Training --&gt; B[Foundation Model]\n    B --&gt; C[Donn\u00e9es sp\u00e9cialis\u00e9es]\n    C --&gt; D[Couche d'adaptation]\n    D --&gt; E[Mod\u00e8le adapt\u00e9]\n\n</code></pre> <p>L'objectif est de se servir d'un mod\u00e8le de base qui pr\u00e9sente une performance \u00e9lev\u00e9 dans des t\u00e2ches g\u00e9n\u00e9ralistes pour le sp\u00e9cialiser \u00e0 travers diff\u00e9rents op\u00e9rations : </p>"},{"location":"Notions_Essentielles/10_modeles_pre_entraines/#le-transfer-learning","title":"Le transfer learning","text":"<p>Cette op\u00e9ration consiste \u00e0 entra\u00eener sp\u00e9cifiquement une ou plusieurs couches de neurones suppl\u00e9mentaire adapt\u00e9es \u00e0 l'objectif final(classification, lab\u00e9lisation, ...). </p> <p>Cet entra\u00eenement n\u00e9cessite \u00e9galement des donn\u00e9es m\u00e9tiers mais en quantit\u00e9 bien moindre que les donn\u00e9es g\u00e9n\u00e9ralistes de base. Cette disproportion n'est pas sans causer parfois des probl\u00e8mes de cohabitation. </p> <p>On aboutit, au final, \u00e0 un mod\u00e8le hybrid\u00e9 qui est souventplus performant qu'un r\u00e9seau entra\u00een\u00e9 seul mais ce n'est pas toujours le cas. </p>"},{"location":"Notions_Essentielles/10_modeles_pre_entraines/#zero-ou-few-shots-learning","title":"Zero ou few shots learning","text":"<p>Cette pratique a \u00e9merg\u00e9 avec les mod\u00e8les de type LLM (Large Language Model) comme GPT. On \u00e9voque l\u00e0 des archictures dont les param\u00e8tres sont sup\u00e9rieurs \u00e0 plusieurs centaines de millions. </p> <p>Elle consiste \u00e0 piloter le mod\u00e8le en lui donnant des instructions ou tr\u00e8s peu d'exemples. On utilise alors sa capacit\u00e9 g\u00e9n\u00e9raliset en l'orientant sp\u00e9cifiquement. Je reviens sur ce ph\u00e9nom\u00e8ne dans l'art du prompting. </p>"},{"location":"Notions_Essentielles/10_modeles_pre_entraines/#utilisation-packagee","title":"Utilisation packag\u00e9e","text":"<p>J'entends par l\u00e0, l'utilisation de solutions propos\u00e9s et d\u00e9j\u00e0 entra\u00een\u00e9s dans des domaines particuliers. </p> <p>Ainsi, vous trouverez chez Amazon ou Google, des services pr\u00eat \u00e0 l'emploi permettant de libre des papiers d'identit\u00e9, des factures, des d\u00e9clarations de revenus (US) ou des documents comptables. </p>"},{"location":"Notions_Essentielles/1_Dataset/","title":"Les jeux de donn\u00e9es (dataset)","text":"<p>L'essor du Deep Learning tient \u00e0 trois facteurs :   - l'augmentation de la puissance de calcul;  - la mise au point de mod\u00e8les plus performants comme les Transformers;  - l'explosion du volume des donn\u00e9es d'apprentissage;</p> <p>Les donn\u00e9es sont le carburant des algorithmes d'IA. Elles entretiennent une relation intime avec les mod\u00e8les d'inf\u00e9rence car, \u00e0 c\u00f4t\u00e9 de l'architecture, elles en sont le constituant essentiel. Leur qualit\u00e9 et leur d\u00e9faut se transmettent tout au long de la cha\u00eene de production du projet de Machine Learning. </p> <p>D\u00e8s lors comprendre leur condition de production, leur structure interne et leur typologie est essentielle. </p>"},{"location":"Notions_Essentielles/1_Dataset/#lelaboration-des-jeux-de-donnees","title":"L'\u00e9laboration des jeux de donn\u00e9es","text":"<p>La mise au point d'important jeux de donn\u00e9es est un enjeu strat\u00e9gique. Nous contribuons, souvent sans le savoir,  \u00e0 l'\u00e9laboration de ce carburant en ajoutant des photos sur les r\u00e9seaux sociaux ou en qualifiant des photos de feux rouges !</p> <p>La collecte et la structuration en vue de l'apprentissage constitue un enjeu en soi et une fraction importante du temps dans une projet d'IA. </p>"},{"location":"Notions_Essentielles/1_Dataset/#les-producteurs","title":"Les producteurs","text":"<p>Il existe deux types de producteurs qui travaillent souvent en collaboration :   - le monde de la recherche universitaire  - les acteurs majeurs de l'IA (Google, Meta, OpenAI, ...)</p> <p>La langue anglaise est largement dominante en raisons de l'origine des acteurs cl\u00e9s \u00e0 l'origine des LLM et du volume de donn\u00e9es o\u00f9 cette langue domine largement. </p> <p>Cela a une influence sur la performance des mod\u00e8les pr\u00e9 entra\u00een\u00e9s car leur utilisation dans un contexte de langues moins fr\u00e9quentes comme le fran\u00e7ais se fait souvent \u00e0 partir de traduction de mauvaise qualit\u00e9. </p> <p>Cette pr\u00e9dominance, avec l'explosion des projets, est lentement remis en cause avec la multiplication des datasets multilingues comme OSCAR.</p>"},{"location":"Notions_Essentielles/1_Dataset/#la-matiere-premiere","title":"La mati\u00e8re premi\u00e8re","text":"<p>Les datasets  sont constitu\u00e9s d'une quantit\u00e9 tr\u00e8s importante de textes d'origines tr\u00e8s diverses :  - Wikipedia - presse g\u00e9n\u00e9raliste et sp\u00e9cialis\u00e9e - webcrawling (Common Crawl) - papiers scientifiques - documents m\u00e9tiers - livres - petites annonces &amp; forums - ...</p> <p>A ce sujet, la transparence n'est pas la r\u00e8gle et les papiers de recherche, \u00e9dit\u00e9s \u00e0 l'appuie des nouveaux mod\u00e8les, ne sont pas pr\u00e9cis sur la r\u00e9partition des mati\u00e8res ou les volumes finaux trait\u00e9s lors de l'apprentissage. </p> <p>Un des sujets cl\u00e9s \u00e0 l'avenir est la r\u00e9cension structur\u00e9e des donn\u00e9es d'entra\u00eenement en s'appuyant sur les normes existantes par exemple en mati\u00e8re de Big Data et une analyse de risque claire \u00e0 ce stade des projets. </p> <p>Une fois la collecte effectu\u00e9e, les donn\u00e9es doivent \u00eatre structur\u00e9es pour r\u00e9pondre \u00e0 des objectifs d'apprentissage pr\u00e9cis. </p>"},{"location":"Notions_Essentielles/1_Dataset/#une-structuration-en-fonction-des-objectifs","title":"Une structuration en fonction des objectifs","text":"<p>On distingue deux types d'approche qui sont li\u00e9 directement au type de donn\u00e9es \u00e0 fournir au mod\u00e8le :  - l'approche supervis\u00e9 (supervised learning) qui consiste \u00e0 qualifier (labeliser) les textes. Une t\u00e2che typique es la classification (spam/non spam) qui n\u00e9cessite en amont une qualification humaine - l'approche non supervis\u00e9 (unsupervised learning) qui consiste \u00e0 fournir des donn\u00e9es sans labelisation pour des t\u00e2ches de regroupement (clustering) ou de d\u00e9tection d'anomalies. </p> <p>En mati\u00e8re textuelle, il est souvent fait recours \u00e0 une mani\u00e8re automatique de cr\u00e9er des donn\u00e9es labelis\u00e9es (self supervised learning). Par exemple, un mod\u00e8le qui vise \u00e0 apprendre \u00e0 g\u00e9n\u00e9rer des mots a uniquement besoin de phrases en entr\u00e9e. Le label est constitu\u00e9 par le mot qui est masqu\u00e9 et qui doit \u00eatre d\u00e9couvert par le mod\u00e8le. </p> <p>Cette caract\u00e9ristique est tr\u00e8s importante \u00e0 comprendre car elle fait, qu'en mati\u00e8re de langage, on dispose d'une mati\u00e8re abondante et peu cher \u00e0 produire.</p> <p>Ainsi, en mati\u00e8re de NLP, les deux types de datasets cohabitent. </p>"},{"location":"Notions_Essentielles/1_Dataset/#typologie-des-datasets","title":"Typologie des datasets","text":""},{"location":"Notions_Essentielles/1_Dataset/#datasets-generalistes","title":"Datasets g\u00e9n\u00e9ralistes","text":"<p>Ils sont constitu\u00e9s d'association de contenus extr\u00eamement vari\u00e9s associ\u00e9 \u00e0 une volum\u00e9trie tr\u00e8s importante. </p> <p>Voici un exemple de r\u00e9partition des donn\u00e9es utilis\u00e9es pour l'entra\u00eenement du mod\u00e8le LLaMa de Meta :  </p> <p>L'objectif d'embrasser une grande partie de l'\u00e9tendue de la production textuelle humaine afin d'entra\u00eener un mod\u00e8le qui a vu \u00e9normement de cas d'agencement de la langue. Ils sont souvent \u00e0 l'origine de mod\u00e8les servant de fondation (Foundation Model) \u00e0 des architectures plus sp\u00e9cialis\u00e9s sur lesquels je reviendrai. </p>"},{"location":"Notions_Essentielles/1_Dataset/#les-datasets-specialises","title":"Les datasets sp\u00e9cialis\u00e9s","text":"<p>Il y a deux mani\u00e8re de sp\u00e9cialiser un dataset :  - en fonction de objectifs de l'entra\u00eenement et l\u00e0 on touche \u00e0 sa structure  - en fonction de la mati\u00e8re (droit, m\u00e9decine, chimie, ...) sur laquelle on souhaite sp\u00e9cialiser notre mod\u00e8le. </p> <p>Voici deux exemples de datasets sp\u00e9cialis\u00e9s dans le droit :</p> <p>1 - le premier est le https://huggingface.co/datasets/rcds/swiss_judgment_prediction/viewer/fr/train</p> <p>Ce dataset sert \u00e0 entra\u00eener un classifieur binaire (\"approval\", \"dismissal\") \u00e0 partir de certaines donn\u00e9es. d'une d\u00e9cision de justice. </p> <p></p> <p>2 - Le deuxi\u00e8me est un dataset contenant un tr\u00e8s large corpus de jurisprudences, directives et r\u00e9glements de l'Union europ\u00e9enne (EURLEX)</p> <p>Ce jeu de donn\u00e9es peut servir \u00e0 entra\u00eener un g\u00e9n\u00e9rateur de language sp\u00e9cialis\u00e9 dans le domaine juridique.</p> <p></p> <p>Je r\u00e9f\u00e9rence dans la partie 'Ressources', les datasets sp\u00e9cialis\u00e9s en droit. </p>"},{"location":"Notions_Essentielles/1_Dataset/#les-donnees-dapprentissage","title":"Les donn\u00e9es d'apprentissage","text":"<p>Pendant l'entra\u00eenement, les jeux de donn\u00e9es sont g\u00e9n\u00e9ralement divis\u00e9s en sous-parties r\u00e9pondant \u00e0 des objectifs diff\u00e9rents :</p> <ul> <li>la partie \"training\" sert \u00e0 entra\u00eener le mod\u00e8le</li> <li>le jeu de donn\u00e9es de validation vise \u00e0 ajuster les param\u00e8tres d'apprentissage du mod\u00e8le</li> <li>enfin, la partie de \"test\" sert \u00e0 le tester, c'est \u00e0 dire \u00e0 voir son comportement sur des donn\u00e9es qu'il n'a pas vu.</li> </ul> <p>Cette phase est souvent tr\u00e8s couteuse en temps machine et pose de nombreux probl\u00e8mes techniques. S'il est possible d'entra\u00eener de petits mod\u00e8les de quelques millions de param\u00e8tres, les mod\u00e8les comme GPT ne peuvent \u00eatre produit que par des organisations qui ont des moyens financiers et humains tr\u00e8s importants. Cette \u00e9tape pose des enjeux particuliers qui fait l'objet de travaux de recherche intense. </p>"},{"location":"Notions_Essentielles/1_Dataset/#les-donnees-devaluation-benchmark","title":"Les donn\u00e9es d'\u00e9valuation (benchmark)","text":"<p>Les mod\u00e8les font l'objet d'une recherche intense et, en la mati\u00e8re, la cr\u00e9ativit\u00e9 est souvent d\u00e9brid\u00e9e. </p> <p>Pour \u00e9tablir des comparaisons fiables entre ces mod\u00e8les, le monde acad\u00e9mique a \u00e9laborer des datasets dit de benchmark sur plusieurs t\u00e2ches qui permettent d'\u00e9tablir un classement avec une m\u00e9thodologie document\u00e9e. </p> <p>Ces donn\u00e9es servent de points d'entr\u00e9e pour les mod\u00e8les pr\u00e9-entrain\u00e9s. Les sorties attendues \u00e9tant connus, leur performance, \u00e0 l'aide de m\u00e9triques courante (F1-Score, Precision/Recall) peuvent \u00eatre compar\u00e9e. </p> <p>L\u00e0 encore, ces ensembles peuvent faire l'objet d'une approche critique. </p> <p>, n  Liens :  What's in my AI Papier Quality at a Glance: An Audit of Web-Crawled Multilingual Datasets</p>"},{"location":"Notions_Essentielles/1_Dataset/#clinique-des-datasets","title":"Clinique des datasets","text":"<p>L'am\u00e9lioration de la qualt\u00e9 des donn\u00e9es est un sujet multidimensionnel complexe. A chaque \u00e9tape du cycle de vie, de nombreux risques peuvent affecter les donn\u00e9es et donc le mod\u00e8le qui en sortira. </p> <p>Parmi ces risques, on peut citer :  - l'absence de tra\u00e7abilit\u00e9 et de transparence sur la collecte et les op\u00e9rations de traitement - les biais de diff\u00e9rentes natures embarqu\u00e9s dans les donn\u00e9es  - les atteintes \u00e0 la vie priv\u00e9e - les attaques sp\u00e9cifiques comme ldata poisoning - le non respect des lois et r\u00e9glementation en vigeur - le respect des droits des tiers - ... </p> <p>Toutes ces questions, et bien d'autres, constiituent une mati\u00e8re passionnante. J'essayerai de me pencher sur certaines d'entre elles. </p>"},{"location":"Notions_Essentielles/2_Design_modeles/","title":"S\u00e9lection et hyperparam\u00e9trage des mod\u00e8les","text":"<p>Les donn\u00e9es collect\u00e9es et pr\u00e9par\u00e9es doivent \u00eatre inject\u00e9es dans un ou plusieurs types de mod\u00e8les d'apprentissage choisis g\u00e9n\u00e9ralement par le ma\u00eetre d'\u0153uvre en fonction des objectifs et du probl\u00e8me trait\u00e9. Il existe pl\u00e9thore d'algorithmes dans le domaine du Machine Learning qui peuvent r\u00e9pondre \u00e0 diff\u00e9rents objectifs. </p> <p>A ce stade, il faut distinguer deux types d'hyperparam\u00e8tres :</p> <ul> <li>ceux qui d\u00e9finissent l'architecture du mod\u00e8le ; </li> <li>ceux qui sont utilis\u00e9s pendant la phase d'entra\u00eenement. </li> </ul> <p>Param\u00e8tres et hyperparam\u00e8tres</p> <p>Les hyperparam\u00e8tres ne doivent pas \u00eatre confondus avec les param\u00e8tres. Ces derniers - \u00e9galement appel\u00e9 poids - sont les valeurs que le mod\u00e8le acquiert pendant la phase d'apprentissage. Ce sont ces valeurs qui vont permettre au mod\u00e8le de pr\u00e9dir le mot suivant \u00e0 partir d'une s\u00e9quence dans GPT. </p>"},{"location":"Notions_Essentielles/2_Design_modeles/#les-hyperparametres-du-modele","title":"Les hyperparam\u00e8tres du mod\u00e8le","text":"<p>La premi\u00e8re s\u00e9rie d'hyperparam\u00e8tres est relative \u00e0 l'architecture du mod\u00e8le. Lorsqu'il s'agit d'un r\u00e9seau de neurones (Deep Learning), ils sont constitu\u00e9s du type de couche, de leur nombre, des fonctions d'activation utilis\u00e9es, etc. </p> <p>Le plus souvent, le ma\u00eetre d'\u0153uvre ne part pas d'une feuille blanche. Il va s\u00e9lectionner des mod\u00e8les sur \u00e9tag\u00e8re souvent issus du monde de la recherche comme les Transformers.</p> <p>Ces mod\u00e8les peuvent \u00eatre recr\u00e9\u00e9s \u00e0 partir de librairies logicielles qui fournissent les briques \u00e9l\u00e9mentaires comme l'illustre l'exemple ci-apr\u00e8s ou utilis\u00e9s directement via des services en ligne comme AWS ou GCP. </p> <p>Parfois, il s'agit de mixer un mod\u00e8le fig\u00e9 (pr\u00e9-entra\u00een\u00e9) et de lui ajouter une couche entra\u00eenable pour accomplir une t\u00e2che particuli\u00e8re ou l'adapter \u00e0 un domaine sp\u00e9cifique. </p> <p>Voici un bout de code utilisant la librairie pytorch qui met en \u0153uvre un classifieur de texte simple avec une couche lin\u00e9aire. </p> Classifieur de texte<pre><code>class TextClassificationModel(nn.Module):\ndef __init__(self, vocab_size, embed_dim, num_class):\nsuper(TextClassificationModel, self).__init__()\nself.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)  # (1)\nself.fc = nn.Linear(embed_dim, num_class # (2)\nself.init_weights()\ndef init_weights(self): # (3)\ninitrange = 0.5\nself.embedding.weight.data.uniform_(-initrange, initrange)\nself.fc.weight.data.uniform_(-initrange, initrange)\nself.fc.bias.data.zero_()\n</code></pre> <ol> <li>:Cette ligne fournit le type d'embeddings et la taille. On peut modifier la taille ou le type de repr\u00e9sentation des mots. </li> <li>:Cette ligne ajoute une couche lin\u00e9aire \u00e0 notre mod\u00e8le (ax+b). On pourra en ajouter d'autres avec un autre type, etc.</li> <li>:Cette fonction initialise les param\u00e8tres (poids-weights) qui seront appris par le  mod\u00e8le. </li> </ol>"},{"location":"Notions_Essentielles/2_Design_modeles/#les-hyperparametres-dapprentissage","title":"Les hyperparam\u00e8tres d'apprentissage","text":"<p>La deuxi\u00e8me s\u00e9rie d'hyperparam\u00e8tres concerne ceux qui permettent d'entra\u00eener effectivement le mod\u00e8le comme la vitesse, le nombre d'it\u00e9rations, la taille des donn\u00e9es \u00e0 traiter en parall\u00e8le...  </p>"},{"location":"Notions_Essentielles/3_Apprentissage/","title":"L'apprentissage","text":"<p>Un r\u00e9seau de neurones apprend, c'est-\u00e0-dire qu'il ajuste par it\u00e9ration ses param\u00e8tres pour aboutir au r\u00e9sultat souhait\u00e9 : pr\u00e9dir un mot, identifier des entit\u00e9s dans un texte, classifier une clause dans un contrat... </p> <p>L'op\u00e9rateur doit ajuster les hyperparam\u00e8tres comme le nombre d'it\u00e9rations ou la vitesse d'apprentissage pour optimiser cette phase. En cela, un r\u00e9seau de neurones n'apprend pas \"tout seul\", il est n\u00e9cessairement pilot\u00e9 par un humain. Il doit donc \u00eatre possible d'identifier et de tracer les \u00e9l\u00e9ments cl\u00e9s de ce pilotage. </p> <p>Ce pilotage vise \u00e0 optimiser l'apprentissage en fonction des objectifs et des contraintes du projet. Il existe un lien fort entre le r\u00e9glage des hyperparam\u00e8tres d'apprentissage et les m\u00e9triques d'\u00e9valuation.  Cette interaction doit aboutir \u00e0 un mod\u00e8le dont l'entra\u00eenement est jug\u00e9 satisfaisant pour \u00eatre mis en production, c'est-\u00e0-dire utilis\u00e9 concr\u00e9tement seul ou au sein d'un applicatif plus vaste.  </p> <pre><code>graph LR\n  A[Analyse] --&gt; B{Apprentissage};\n  B --&gt; C{Evaluation};\n  C --&gt; |Ok !|D[D\u00e9ploiement];\n  C --&gt;|Nok| A;\n  E[Donn\u00e9es] --&gt;B;</code></pre>"},{"location":"Notions_Essentielles/3_Apprentissage/#lajustement-des-hyperparametres","title":"L'ajustement des hyperparam\u00e8tres","text":"<p>Les hyperparam\u00e8tres sont de deux natures : </p> <ul> <li>les premiers sont relatifs \u00e0 l'architecture du r\u00e9seau de neurones : le nombre de couches, la taille, etc. ;</li> <li>les seconds vont \u00eatre ajust\u00e9s pendant la phase d'apprentissage comme la vitesse, le nombre d'it\u00e9rations, la taille des donn\u00e9es \u00e0 traiter en parall\u00e8le... </li> </ul>"},{"location":"Notions_Essentielles/3_Apprentissage/#illustration-journal-de-sortie-dentrainement-dun-modele","title":"Illustration : journal de sortie d'entra\u00eenement d'un mod\u00e8le","text":"<p>Les lignes suivantes correspondent aux informations produites par l'entra\u00eenement d'un r\u00e9seau de neurones visant \u00e0 classifier des bouts de textes en plusieurs cat\u00e9gories (classes). Voici les informations qu'elles contiennent : </p> <ul> <li>l'epoch est un hyperparam\u00e8tre qui correspond \u00e0 un cycle d'apprentissage sur les donn\u00e9es (un passage entier) ; </li> <li>les donn\u00e9es ne sont pas inject\u00e9es en une fois dans le mod\u00e8le mais sous forme de lots (batches). La taille de ces lots est un hyperparam\u00e8tre ;</li> <li>la m\u00e9trique utilis\u00e9e ici est l'exactitude (accuracy). On voit qu'elle augmente au fur et \u00e0 mesure de l'apprentissage. Elle est \u00e9galement appliqu\u00e9e au jeu de donn\u00e9es de validation (non vue pendant l'entra\u00eenement) pour \u00e9valuer le mod\u00e8le \u00e0 chaque cycle (epoch). </li> </ul> <p><pre><code>| epoch   1 |   500/ 1782 batches | accuracy    0.714\n| epoch   1 |  1000/ 1782 batches | accuracy    0.867\n| epoch   1 |  1500/ 1782 batches | accuracy    0.884\n-----------------------------------------------------------\n| end of epoch   1 | time: 10.58s | valid accuracy    0.883\n-----------------------------------------------------------\n| epoch   2 |   500/ 1782 batches | accuracy    0.906\n| epoch   2 |  1000/ 1782 batches | accuracy    0.903\n| epoch   2 |  1500/ 1782 batches | accuracy    0.905\n-----------------------------------------------------------\n| end of epoch   2 | time:  8.74s | valid accuracy    0.903\n-----------------------------------------------------------\n| epoch   3 |   500/ 1782 batches | accuracy    0.918\n| epoch   3 |  1000/ 1782 batches | accuracy    0.919\n| epoch   3 |  1500/ 1782 batches | accuracy    0.918\n-----------------------------------------------------------\n| end of epoch   3 | time:  8.80s | valid accuracy    0.822\n-----------------------------------------------------------\n| epoch   4 |   500/ 1782 batches | accuracy    0.935\n| epoch   4 |  1000/ 1782 batches | accuracy    0.939\n| epoch   4 |  1500/ 1782 batches | accuracy    0.938\n-----------------------------------------------------------\n| end of epoch   4 | time:  8.82s | valid accuracy    0.910\n</code></pre> *source : https://pytorch.org/tutorials/beginner/text_sentiment_ngrams_tutorial.html?highlight=classification *</p> <p>Les choix op\u00e9r\u00e9s pendant cette phase, comme la s\u00e9lection des m\u00e9triques d'\u00e9valuation, va avoir des cons\u00e9quences sur le rendu final, c'est-\u00e0-dire la capacit\u00e9 du mod\u00e8le \u00e0 pr\u00e9dir. </p> <p>Une fois entra\u00een\u00e9, le mod\u00e8le est fig\u00e9 totalement ou partiellement. On peut alors l'utiliser pour le faire se sp\u00e9cialiser sur certaines t\u00e2ches moyennant un entra\u00eenement compl\u00e9mentaire ou tel quel. </p>"},{"location":"Notions_Essentielles/4_Les%20m%C3%A9triques/","title":"Les m\u00e9triques d'\u00e9valuation","text":"<p>L'\u00e9valuation des mod\u00e8les de machine learning pose des probl\u00e8mes particuliers. Un programme informatique traditionnel prend en entr\u00e9e des donn\u00e9es et fournit un r\u00e9sultat toujours identique (en principe !) en sortie. Cette logique d\u00e9terministe ne peut pas s'appliquer au machine learning et, en particulier, au NLP. </p> <p>Revenons quelques instants sur les objectifs de ces mod\u00e8les. On peut r\u00e9sumer leur finalit\u00e9 sous deux aspects : </p> <ul> <li>la pr\u00e9diction d'une valeur (regression) : le quantum d'une peine, l'indemnisation d'un pr\u00e9judice ou le montant d'une sanction p\u00e9cuniaire ; </li> <li>la classification : la nature de la clause d'un contrat, l'issue d'un pourvoi en cassation (rejet, cassation), le type de mati\u00e8re (droit social, commercial, civil) trait\u00e9 par une d\u00e9cision de justice ou un contrat. Le mod\u00e8le doit d\u00e9terminer \u00e0 quelle classe le texte appartient : il doit lui attribuer un label. </li> </ul> <p>Et GPT, classification ou regression ?  Dans les mod\u00e8les de type [[Glossaire#Decoder]], l'objectif du mod\u00e8le est de pr\u00e9dire un mot en fonction du contexte (la s\u00e9quence des mots pr\u00e9c\u00e9dents). Pour ce faire, il fournit une r\u00e9partition des probabilit\u00e9s concernant chaque mot du vocabulaire. En cela, il s'agit d'un classifieur multi-classes. </p>"},{"location":"Notions_Essentielles/4_Les%20m%C3%A9triques/#processus-devaluation-inter-modeles-les-benchmarks","title":"Processus d'\u00e9valuation inter-mod\u00e8les : les benchmarks","text":"<p>Le monde acad\u00e9mique a \u00e9labor\u00e9, au fil des ans, des jeux de donn\u00e9es de r\u00e9f\u00e9rences permettant d'\u00e9valuer les diff\u00e9rents mod\u00e8les. On peut faire trois remarques \u00e0 propos de ces dataset : </p> <ul> <li>en quelques ann\u00e9es, on est pass\u00e9 de donn\u00e9es d'\u00e9valuation mono-t\u00e2che (reconnaissance d'entit\u00e9s nomm\u00e9es, Part Of Speech...) \u00e0 des approches plus g\u00e9n\u00e9ralistes et se rapprochant des activit\u00e9s humaines comme r\u00e9pondre \u00e0 des questions ou dialoguer ;</li> <li>ils permettent d'\u00e9tablir des comparaisons entre les mod\u00e8les en pr\u00e9sentant des jeux de donn\u00e9es strictement identiques ;</li> <li>les m\u00e9triques finalement calcul\u00e9es sont agnostiques vis-\u00e0-vis des mod\u00e8les. </li> </ul>"},{"location":"Notions_Essentielles/4_Les%20m%C3%A9triques/#les-differentes-metriques","title":"Les diff\u00e9rentes m\u00e9triques","text":""},{"location":"Notions_Essentielles/4_Les%20m%C3%A9triques/#exemple-identifier-une-clause-penale","title":"Exemple : identifier une clause p\u00e9nale","text":"<p>Prenons comme exemple un programme charg\u00e9 d'identifier la nature d'une clause dans un contrat. Dans le cadre d'un audit, on l'entra\u00eene pour reconna\u00eetre la pr\u00e9sence de clauses p\u00e9nales. Il op\u00e9re une classification binaire : la clause est une clause p\u00e9nale (positif) ou n'est pas une clause p\u00e9nale (n\u00e9gatif). </p> <p>Pour entra\u00eener le mod\u00e8le, on lui fournit un grand nombre d'exemples de clauses avec deux colonnes : la premi\u00e8re comprend le texte, la seconde comprend la classe (0 : pas une clause p\u00e9nale, 1: clause p\u00e9nale). </p> <p>Une fois entra\u00een\u00e9, on lui soumet un jeu de donn\u00e9es identiques qu'il n'a pas vu lors de la phase d'apprentissage, et on lui demande de classer les clauses. </p> <p>Voici les r\u00e9sultats : </p> Contrats clause p\u00e9nale ? Clause 1 [0.4, 0.6] Clause 2 [0.6, 0.4] Clause 3 [0.9, 0.1] Clause 4 [0.2, 0.8] Clause n [0.7, 0.3] <p>On constate avec \u00e9tonnement  que le mod\u00e8le ne sort pas un 1 (oui, il y a une clause p\u00e9nale) et un 0 (non, pas de pr\u00e9sence de clause p\u00e9nale). Le r\u00e9sultat en sortie est constitu\u00e9 de deux valeurs qui correspondent \u00e0 la probabilit\u00e9 que la clause soit oui (1) ou non (0) une clause p\u00e9nale. Nous ne sommes pas dans une logique automatique : le mod\u00e8le ne fait que produire une estimation probabiliste. Il n'est pas certain de la classe d'appartenance. </p> <p>Par exemple, pour la clause 1, le mod\u00e8le estime qu'il y a 60% (0,6) de chance qu'elle soit une clause p\u00e9nale (classe 1 ou positif) et 40% qu'elle n'en soit pas une (classe 0 ou n\u00e9gatif). </p> <p>La somme de ces deux nombres est syst\u00e9matiquement 1. En effet, il y a 100% de chance que la clause appartienne \u00e0 une seule des deux cat\u00e9gories. C'est un classifieur binaire. Si l'on souhaitait classer une clause selon plusieurs classes (clause p\u00e9nale, clause abusive, de non-concurrence), la somme des probabilit\u00e9s serait toujours 1 et le mod\u00e8le produirait une r\u00e9partition des probabilit\u00e9s entre les classes. Pour obtenir la plus probable, on s\u00e9lectionnerait la classe ayant la probabilit\u00e9 la plus forte. </p> <p>D\u00e8s lors, on peut se poser deux questions : </p> <ul> <li>\u00e0 partir de quel taux de probabilit\u00e9, estime-t-on que l'on est en pr\u00e9sence d'une clause p\u00e9nale ? </li> <li>si l'on fixe ce taux, disons \u00e0 50%, comment le mod\u00e8le classe-t-il mes clauses par rapport \u00e0 la r\u00e9alit\u00e9 ? Dit autrement, quel est son taux d'erreur ? </li> </ul> <p>Pour \u00e9valuer ce taux, il existe plusieurs m\u00e9triques qu'il est important de conna\u00eetre. Ces m\u00e9triques s'appliquent \u00e0 toutes les op\u00e9rations de classification. Elles ont des impacts directs sur l'\u00e9valuation des syst\u00e8mes d'Intelligence artificielle bien au-del\u00e0 du NLP. </p>"},{"location":"Notions_Essentielles/4_Les%20m%C3%A9triques/#lexactitude-accuracy","title":"L'exactitude (accuracy)","text":"<p>C'est la mesure la plus simple \u00e0 comprendre. Parmi toutes les clauses que je lui ai montr\u00e9es, combien de fois le mod\u00e8le a-t-il pr\u00e9dit correctement la pr\u00e9sence d'une clause p\u00e9nale ? </p> <p>Imaginons  que notre jeu de donn\u00e9es d'\u00e9valuation porte sur 1000 clauses. Dans notre jeu de test, on sait que 300 clauses sont des clauses p\u00e9nales. </p> <p>Le r\u00e9sultat du classement op\u00e9r\u00e9 par le mod\u00e8le est le suivant : </p> <ul> <li>240 clauses p\u00e9nales class\u00e9es comme clause p\u00e9nale (Vrai positif : 1 class\u00e9 en 1)</li> <li>80 non clauses p\u00e9nales class\u00e9es comme clause p\u00e9nale (Faux positif : 0 class\u00e9 en 1)</li> <li>620 non clauses p\u00e9nales class\u00e9es comme non clause p\u00e9nale (Vrai n\u00e9gatif : 0 class\u00e9 en 0)</li> <li>60 clauses p\u00e9nales class\u00e9es comme non clause p\u00e9nale (Faux n\u00e9gatif : 1 class\u00e9 en 0 )</li> </ul> <p>Le mod\u00e8le a fait des erreurs ! C'est-\u00e0-dire qu'il a mal class\u00e9 certaines clauses. </p> <p></p> <p>Si l'on veut \u00e9valuer l'exactitude du mod\u00e8le, on peut \u00e9valuer le nombre de fois o\u00f9 il attribue correctement la bonne classe aux clauses : sur 1000 clauses, il a class\u00e9 correctement respectivement 620 et 240 clauses correctement soit 860/1000 ou 86% d'exactitude. C'est un tr\u00e8s bon score. Trop bon ? </p> <p>Imaginons que le mod\u00e8le ait class\u00e9 toutes les clauses en non clause p\u00e9nale soit la classe 0. Il aurait donc class\u00e9 comme n\u00e9gatives et avec exactitude 70% des clauses puisqu'on sait que 700/1000 clauses ne sont pas des clauses p\u00e9nales.  Il est relativement performant mais est-il utile ? En effet, si l'on veut auditer un ensemble de contrats et identifier la pr\u00e9sence de clauses sp\u00e9cifiques, il faut pouvoir discriminer les clauses p\u00e9nales des autres. Pr\u00e9cis\u00e9ment, cette mesure ne donne que la performance \u00e0 classer correctement mais pas la performance \u00e0 attribuer la classe qui nous int\u00e9resse. C'est pour cela, qu'il faut \u00e9laborer une autre approche en utilisant une technique appel\u00e9e la matrice de confusion. </p>"},{"location":"Notions_Essentielles/4_Les%20m%C3%A9triques/#la-matrice-de-confusion","title":"La matrice de confusion","text":"<p>La matrice de confusion est construite en comparant les pr\u00e9dictions faites par le mod\u00e8le et la r\u00e9alit\u00e9. Elle va \u00eatre utilis\u00e9e pour calculer les m\u00e9triques de classification. </p> <p>Dans notre exemple, cette matrice se pr\u00e9sente de la mani\u00e8re suivante : </p> Pr\u00e9diction : clause p\u00e9nale (1) Pr\u00e9diction : pas clause p\u00e9nale (0) R\u00e9alit\u00e9 : clause p\u00e9nale (1) 240 60 R\u00e9alit\u00e9 : pas clause p\u00e9nale (0) 80 620 <p>Les lignes repr\u00e9sentent la r\u00e9alit\u00e9, c'est-\u00e0-dire les clauses associ\u00e9es aux classes dans notre jeu de donn\u00e9es d'\u00e9valuation. Les colonnes repr\u00e9sentent les pr\u00e9dictions faites par le mod\u00e8le.  Dans la colonne 1, le mod\u00e8le a pr\u00e9dit correctement 240 clauses (Vrai positif) et il s'est tromp\u00e9 sur 80 clauses mal attribu\u00e9es (Faux positif).</p> <p>Cependant, on peut modifier ce chiffre assez facilement en jouant sur le seuil d'attribution au-del\u00e0 duquel le mod\u00e8le attribue la classe 1 ou 0. On a vu plus haut que les donn\u00e9es de sortie sont des probabilit\u00e9s que la clause appartienne \u00e0 la classe 1 ou 0 et non directement 1 ou 0. Il est possible de modifier le seuil de d\u00e9clenchement. Par exemple, on peut estimer qu'il faut que le mod\u00e8le attribue une probabilit\u00e9 de plus 0,7 pour consid\u00e9rer qu'une clause est une clause p\u00e9nale. Si on joue sur ce facteur, que se passe t-il ? </p> <p>Le graphique suivant illustre les cons\u00e9quences de la modification du seuil de d\u00e9clenchement. </p> <p></p> <p>Si l'on augmente le seuil au-del\u00e0 duquel le mod\u00e8le consid\u00e8re que la clause est une clause p\u00e9nale (classe 1), il y a un effet de vases communicants :</p> <ul> <li>les faux positifs diminuent et viennent alimenter les vrais n\u00e9gatifs ;</li> <li>les vrais positifs diminuent et viennent alimenter les faux n\u00e9gatifs.</li> </ul> <p>Le choix de ce seuil a des effets concrets sur les pr\u00e9visions et les objectifs que l'on se fixe.  Si l'on privil\u00e9gie un seuil \u00e9lev\u00e9, on d\u00e9tectera moins de clauses p\u00e9nales dans nos documents mais avec une certitude plus grande.  Dans le m\u00eame temps, beaucoup de clauses p\u00e9nales ne seront pas identifi\u00e9es comme telles (augmentation des Faux N\u00e9gatifs). A l'inverse, si l'on baisse le seuil de d\u00e9clenchement, on aura beaucoup de clauses non p\u00e9nales mal class\u00e9es (Faux Positifs) ce qui demandera un travail suppl\u00e9mentaire en aval. </p> <p>Ces enjeux ne sont pas propres au NLP. Leur compr\u00e9hension permet de placer le d\u00e9bat sur d'autres terrains si l'on substitue \u00e0 la d\u00e9tection de clause, un classement concernant la dangerosit\u00e9 d'un individu ou son risque de r\u00e9cidive en mati\u00e8re p\u00e9nale. Le seuil de d\u00e9clenchement illustre des probl\u00e8matiques plus fondamentales entre libert\u00e9 (seuil \u00e9lev\u00e9) et s\u00e9curit\u00e9 (seuil bas). </p> <p>On a d\u00e9taill\u00e9 les effets du seuil de d\u00e9clenchement sur notre matrice de confusion mais nous n'avons pas d\u00e9taill\u00e9 les m\u00e9triques qu'on peut en tirer. Les m\u00e9triques de base des mod\u00e8les de classification sont la Pr\u00e9cision et le Recall (Rappel).</p>"},{"location":"Notions_Essentielles/4_Les%20m%C3%A9triques/#precision-et-recall","title":"Pr\u00e9cision et Recall","text":"<p>Lors de l'audit de documents, et si l'on souhaite identifier des clauses sp\u00e9cifiques, on aimerait identifier deux indicateurs pour \u00e9valuer notre syst\u00e8me. </p> <p>Le premier, nomm\u00e9 Pr\u00e9cision, mesure le taux d'erreurs du mod\u00e8le quand il fait une pr\u00e9diction positive. Pour cela, il suffit de faire le rapport entre le nombre de Vrai Positif (VP) divis\u00e9 par la totalit\u00e9 des pr\u00e9dictions positives (VP+FP ). Plus ce taux est \u00e9lev\u00e9, plus le mod\u00e8le est pr\u00e9cis. </p> <p>Toutefois, cet indicateur se borne \u00e0 compter, parmi les clauses s\u00e9lectionn\u00e9es (cf. schema supra), celles qui sont bien class\u00e9es. Mais il existe \u00e9galement des clauses positives qui sont class\u00e9es comme n\u00e9gatives (Faux N\u00e9gatif). Par cons\u00e9quent, cet indicateur ne r\u00e9pond pas \u00e0 la question sur l'efficacit\u00e9 \u00e0 s\u00e9lectionner les clauses positives. </p> <p>Pour illustrer cela, prenons un cas extr\u00eame. Mettons un seuil de d\u00e9clenchement au-del\u00e0 de 0.8. Dans ce cas, selon notre sch\u00e9ma, il n'y a plus de Faux Positif (FP), la Pr\u00e9cision est donc de 100%. Mais quid des nombreux Faux N\u00e9gatifs cr\u00e9\u00e9 par ce seuil ? Comment affectent-ils mon mod\u00e8le ? </p> <p>Pour r\u00e9pondre \u00e0 cette question, une autre mesure, le Recall ou Rappel permet de calculer le taux de positifs calcul\u00e9 par le mod\u00e8le en prenant en compte l'ensemble des clauses positives (VP +FN) et non simplement celles que le mod\u00e8le consid\u00e8re comme positives. </p> <p>D\u00e8s lors, quel est le rapport entre ces deux indicateurs ?</p> <p>Dans notre exemple du seuil \u00e0 80%, la Pr\u00e9cision \u00e9tait mont\u00e9e \u00e0 100% mais quid du Recall ?  Le Recall \u00e9tait descendu plomb\u00e9 par le nombre de Faux N\u00e9gatifs cr\u00e9\u00e9s par cette modification du seuil. Il y a donc une liaison entre les deux indicateurs. Si je baisse mon seuil de d\u00e9clenchement \u00e0 10%, le mod\u00e8le a maintenant un Recall de 100% selon notre sch\u00e9ma. En effet, il a s\u00e9lectionn\u00e9 correctement tous les positifs puisqu'il met toutes les clauses dans le m\u00eame panier ! La Pr\u00e9cision plonge en raison de l'augmentation des Faux Positifs. </p> <p>Le but est de trouver un seuil de d\u00e9clenchement qui soit optimal, c'est-\u00e0-dire qui maximise la paire Pr\u00e9cision/Recall en fonction des objectifs fix\u00e9s. La mani\u00e8re math\u00e9matique de trouver et d'\u00e9valuer cet optimum d\u00e9passe largement l'objet de cet article. </p> <p>Toutefois, on peut aborder cet optimum en se posant une question simple : est-ce que l'objectif est d'\u00eatre pr\u00e9cis - peu de faux positifs - ou d'\u00eatre plus exhaustif  dans la d\u00e9tection en minimisant les faux n\u00e9gatifs ?  Prenons l'exemple, de la d\u00e9tection des fausses nouvelles (fake news) : </p> <ul> <li>une grande Precision minimisera les Faux Positifs et donc favorisera la libert\u00e9 d'expression : on ne d\u00e9tecte pas toutes les fake news mais quand on les d\u00e9tecte, le syst\u00e8me est plus pr\u00e9cis ou \"confiant\" ; </li> <li>un grand Recall maximisera les Faux Positifs : on identifie plus de fake news (Vrais Positifs) mais l'effet de bord est l'augmentation du nombre de textes mal classifi\u00e9s (Faux Positifs) en portant atteinte \u00e0 la libert\u00e9 d'expression. </li> </ul> <p>Pour trouver un \u00e9quilibre entre ces deux m\u00e9triques, il existe un indicateur qui les synth\u00e9tise : le F1 Score.</p>"},{"location":"Notions_Essentielles/4_Les%20m%C3%A9triques/#f1-score","title":"F1-Score","text":"<p>Le F1-Score est la moyenne des deux taux, Pr\u00e9cision et Recall. </p> <p>F1-Score = 2 x ( (Precision x Recall) / (Precision + Recall) )</p> <p>Cette moyenne suit, par construction, l'\u00e9volution de ces deux indicateurs. Elle varie entre 0 et 1. Plus elle est proche de 1, meilleur est le mod\u00e8le. </p> <p>La Precision et le Recall n'\u00e9voluent pas exactement de la m\u00eame mani\u00e8re. M\u00e9caniquement quand l'un baisse l'autre n'augmente pas d'autant. Cette dissociation fait qu'il existe un compromis entre ces deux indicateurs. Ce compromis peut \u00eatre trouv\u00e9 en optimisant le F1-Score.</p> <p>Pour reprendre notre exemple des fake news, on peut vouloir un syst\u00e8me qui, tout en pr\u00e9servant la libert\u00e9 d'expression assure une d\u00e9tection assez large de ces contenus. Cet \u00e9quilibre sera trouv\u00e9 gr\u00e2ce \u00e0 cette m\u00e9trique. </p> <p>Et les humains ? Il est courant de trouver le F1 Score des humains dans les benchmarks pour nous comparer aux mod\u00e8les. En effet, les humains n'ont pas un score de 100 % car ils font des erreurs surtout dans les t\u00e2ches \u00e9labor\u00e9es. </p>"},{"location":"Notions_Essentielles/4_Les%20m%C3%A9triques/#les-autres-metriques","title":"Les autres m\u00e9triques...","text":"<p>Les t\u00e2ches effectu\u00e9es par les mod\u00e8les sont parfois plus complexes qu'une classification binaire. Pour accompagner ces raffinements, les m\u00e9triques sont adapt\u00e9es comme dans le cadre de la classification multi-classes ou sont sp\u00e9cifiques \u00e0 un domaine comme la traduction (BLEU) ou intrins\u00e8que \u00e0 un mod\u00e8le (Perplexity). Cela fera l'objet de d\u00e9veloppements ult\u00e9rieurs. </p>"},{"location":"Notions_Essentielles/5_representation_des_mots_embeddings/","title":"La signature s\u00e9mantique des mots","text":""},{"location":"Notions_Essentielles/5_representation_des_mots_embeddings/#comment-capturer-le-sens-des-mots","title":"Comment capturer le sens des mots ?`","text":""},{"location":"Notions_Essentielles/5_representation_des_mots_embeddings/#lhypothese-distributionnelle","title":"L'hypoth\u00e8se distributionnelle","text":"<p>Les chercheurs ont propos\u00e9 plusieurs m\u00e9thodes pour capturer la s\u00e9mantique des mots. Elles ont toutes un point commun : regarder le contexte du mot,  \"dis-moi qui tu fr\u00e9quentes et je te donnerai ton sens\" ! Le voisinage d'un mot, les autres mots qu'il fr\u00e9quente produisent le sens. C'est ce qu'on appelle le contexte.</p> <p>Les mots qui interviennent dans des contextes similaires tendent \u00e0 avoir une signification proche. On appelle cette approche l\u2019hypoth\u00e8se de distribution : les mots qui sont s\u00e9mantiquement proches tendent \u00e0 \u00eatre utilis\u00e9s dans le m\u00eame contexte.</p>"},{"location":"Notions_Essentielles/5_representation_des_mots_embeddings/#compter-le-nombre-de-mots-par-document","title":"Compter le nombre de mots par document","text":"<p>Prenons plusieurs phrases afin d'illustrer notre propos. </p> <pre><code>phrases = [\n'les normes prot\u00e9gent les donn\u00e9es', 'le RGPD prot\u00e9ge les donn\u00e9es personnelles', 'les cybercriminelles volent les donn\u00e9es', 'les juges rendent la justice', 'les juristes prot\u00e9gent des donn\u00e9es', \"la conformit\u00e9 respecte les normes\"]\n</code></pre> <p>La premi\u00e8re approche est de compter le nombre de mots dans chacune d'elles. On a supprim\u00e9 les mots non signifiants (stopwords) comme les d\u00e9terminants pour ne conserver que les mots ayant une valeur s\u00e9mantique. </p> <p></p> <p>Pour chaque phrase, on a r\u00e9f\u00e9renc\u00e9 les mots qui y sont contenus. La phrase est le contexte du mot. </p> <p>Le probl\u00e8me de cette approche est que chaque mot a un poids \u00e9quivalent. Les d\u00e9terminants ont le m\u00eame poids que les verbes mais leur int\u00e9r\u00eat en terme s\u00e9mantique est inf\u00e9rieur. </p> <p>Pour r\u00e9soudre ce probl\u00e8me, on peut utiliser une technique tr\u00e8s simple appel\u00e9e TF-IDF. </p> <p>L'id\u00e9e est d'attribuer un poids aux mots en fonction de deux facteurs : </p> <ul> <li>TF : leur nombre d'apparitions dans le texte (ici des phrases) ;</li> <li>IDF : leur nombre d'apparitions dans tout le corpus (dans toutes les phrases).</li> </ul> <p></p> <p>D\u00e9sormais, les mots sont r\u00e9partis en fonction de leur poids. On voit que le mot \"donn\u00e9es\" a des valeurs dans toutes les phrases sauf une. Si on lit la colonne le concernant, on voit la distribution des contextes. Par exemple, il ne p\u00e8se rien en ce qui concerne la justice ou les juges dans notre corpus puisqu'il n'y appara\u00eet pas. On voit que ces superpositions permettent de donner un sens contextualis\u00e9 au mot. </p>"},{"location":"Notions_Essentielles/5_representation_des_mots_embeddings/#prendre-en-compte-le-contexte-des-mots","title":"Prendre en compte le contexte des mots","text":"<p>Dans notre exemple pr\u00e9c\u00e9dent, le contexte est une phrase mais on peut g\u00e9n\u00e9raliser \u00e0 une fen\u00eatre autour du mot, c'est-\u00e0-dire n mot(s) avant et n mot(s) apr\u00e8s. Ainsi, notre contexte n'est plus la phrase mais les mots qui l'entourent avec une fen\u00eatre plus ou moins large. </p> <p>On isole un (n=1) mot avant et un apr\u00e8s un autre puis on reconstitue des phrases (les contextes). On fait le m\u00eame calcul TF-IDF et on obtient la matrice suivante : </p> <p></p> <p>En d\u00e9coupant de la sorte, un plus grand nombre de contextes apparaissent donc on affine dans quel espace s\u00e9mantique les mots sont r\u00e9f\u00e9renc\u00e9s. Si on isole les colonnes, on obtient des tableaux de nombres qui positionnent le mot dans un espace vectoriel. </p> <p>Dans notre exemple, le contexte est pr\u00e9sent\u00e9 avec les mots servant \u00e0 le calculer mais on peut le g\u00e9n\u00e9raliser. On aura un contexte \u00e9voquant la justice, la s\u00e9curit\u00e9, la conformit\u00e9, etc.</p> <p>Ce tableau de nombres, appel\u00e9 vecteur, est la signature s\u00e9mantique du mot. Il r\u00e9f\u00e9rence les diff\u00e9rents sens que peut prendre un mot. </p> <p>Pour expliciter encore notre propos, voici des mots avec des contextes plus clivants que notre exemple pr\u00e9c\u00e9dent. </p> Avocat Juge Cin\u00e9ma Litterature Aspirine Justice 0,78 0,77 0,18 0,15 0,04 Nourriture 0,2 0,06 0,18 0,23 0,09 Soin 0,2 0,22 0,11 0,10 0,7 <p>Ce tableau fournit une quantification des pour chaque mot de la quantit\u00e9 de sens/contexte qu'il contient. L'avocat \u00e9voque la justice (0,78) mas \u00e9galement la nourriture (0,2). Le cin\u00e9ma peut \u00eatre associ\u00e9, par ses repr\u00e9sentations, aux trois contextes : justice, nourriture et soin mais moins qu'aspirine pour ce dernier item. </p> <p>En poursuivant, notre raisonnement, on peut lire le tableau de deux mani\u00e8res : </p> <ul> <li>en ligne, on voit la r\u00e9partition des mots sur chaque contexte ;  </li> <li>en colonne, on voit le poids de chaque contexte au sein d'un mot.</li> </ul> <p>La colonne repr\u00e9sente le vecteur du mot. A partir de cette repr\u00e9sentation, nous pouvons faire des op\u00e9rations math\u00e9matiques comme calculer la similarit\u00e9, faire des soustractions ou des additions. </p> <p>En pratique, l'obtention de ces vecteurs et des contextes est le r\u00e9sultat de l'entra\u00eenement d'un r\u00e9seau de neurones. Les sens/contextes sont repr\u00e9sent\u00e9s sous forme d'indice dans un tableau et non explicitement comme dans mon exemple. </p>"},{"location":"Notions_Essentielles/5_representation_des_mots_embeddings/#un-exemple-de-construction-de-vecteurs-word2vec","title":"Un exemple de construction de vecteurs : word2vec","text":"<p>En 2013, un papier de recherche, intitul\u00e9  \"Efficient Estimation of Word Representations in Vector Space\", montre comment construire ces repr\u00e9sentations \u00e0 partir d'un r\u00e9seau de neurones.</p> <p>La solution est d'entra\u00eener un r\u00e9seau de neurones \u00e0 d\u00e9couvrir un mot masqu\u00e9 entour\u00e9 de deux mots qu'il conna\u00eet ou l'inverse : d\u00e9couvrir les mots qui entourent un mot connu.</p> <p>Au d\u00e9part, on choisit la taille de repr\u00e9sentation d'un mot, c'est-\u00e0-dire sa dimension ou le nombre de sens/contextes diff\u00e9rents qu'il pourrait prendre. Si l'on prend une dimension de 64, on initialisera les 64 valeurs de mani\u00e8re al\u00e9atoire. Dans ce cas, chaque case a une valeur m\u00eame minime \u00e0 la diff\u00e9rence de nos exemples pr\u00e9c\u00e9dents o\u00f9 certaines \u00e9taient nulles. </p> <p>Puis on construit le vocabulaire \u00e0 partir de notre corpus, c'est-\u00e0-dire l'ensemble des mots contenus dans nos textes. </p> <p>Viens ensuite le choix du mode d'apprentissage. Si l'on opte pour masquer un mot, le mod\u00e8le devra deviner le mot masqu\u00e9 en fonction des n mots avant-apr\u00e8s. </p> <p>Pendant l'entra\u00eenement, le r\u00e9seau doit attribuer la probabilit\u00e9, parmi tous les mots du vocabulaire, que chaque mot soit le mot manquant. </p> <p>Au d\u00e9part, les param\u00e8tres \u00e9tant al\u00e9atoires, il va fortement se tromper. </p> <p>Un m\u00e9canisme math\u00e9matique permet de boucler sur le r\u00e9seau en indiquant quels sont les param\u00e8tres (les poids) qui sont reponsables des erreurs les plus manfestes. Ce processus it\u00e9ratif est \u00e9valu\u00e9 \u00e0 chaque cycle et le r\u00e9seau doit am\u00e9liorer son apprentissage pour minimiser ses erreurs. </p> <p>Arriv\u00e9 en fin de processus, les param\u00e8tres optimums sont trouv\u00e9s. Ces param\u00e8tres correspondent au poids des 64 contextes-sens associ\u00e9s \u00e0 un mot. </p> <p>On peut alors extraire nos vecteurs associ\u00e9s \u00e0 chaque mot pour les r\u00e9utiliser pour d'autres t\u00e2ches comme de la recherche, de la classification, etc. </p>"},{"location":"Notions_Essentielles/5_representation_des_mots_embeddings/#exemple-word2vec-entraine-sur-la-directive-nis-2","title":"Exemple : word2vec entra\u00een\u00e9 sur la directive NIS 2","text":"<p>Voici quelques lignes de code qui illustrent une repr\u00e9sentation vectorielle de mots \u00e0 partir du texte de la [directive NIS 2]  (https://eur-lex.europa.eu/legal-content/FR/TXT/?uri=uriserv%3AOJ.L_.2022.333.01.0080.01.FRA&amp;toc=OJ%3AL%3A2022%3A333%3A). </p> <p>Afin de vous \u00e9pargner les \u00e9tapes de pr\u00e9traitrement, sans int\u00e9r\u00eat dans notre cadre, j'ai pr\u00e9-entra\u00een\u00e9 un mod\u00e8le avec librairie Gensim.</p> <p><pre><code>!pip install gensim\nfrom gensim.models import Word2Vec\nmodel = Word2Vec.load('nis2.model')\nmot = \"s\u00e9curit\u00e9\"\nprint(f\"Voici les 10 premiers nombres repr\u00e9sentant les coordonn\u00e9es du mot {mot} : \\n {model.wv[mot][:10]}\\n\")\nprint(\"Cette repr\u00e9sentation permet notamment de rechercher les mots les plus similaires dans le m\u00eame corpus :\", model.wv.most_similar('identification'))\n```\n</code></pre> <code>Voici les 10 premiers nombres repr\u00e9sentant les coordonn\u00e9es du mot s\u00e9curit\u00e9 : [-0.21285973 0.5637689 0.20553416 -0.06742156 0.03788706 -0.7225273 0.11224744 0.9837986 -0.36839244 -0.33970815]</code></p> <p><code>Cette repr\u00e9sentation permet notamment de rechercher les mots les plus similaires dans le m\u00eame corpus : [('fiabilit\u00e9', 0.9851323962211609), ('signatures', 0.9841110110282898), ('listes', 0.9839881658554077), ('cadre', 0.9838947653770447), ('protection', 0.9838393926620483), ('niveau', 0.9837104082107544), ('partie', 0.9837022423744202), ('\u00e9lectroniques', 0.983534574508667), ('directive', 0.9835230112075806), ('l\u2019utilisation', 0.9835212230682373)]</code> ``</p>"},{"location":"Notions_Essentielles/5_representation_des_mots_embeddings/#encore-plus-de-contextes","title":"Encore plus de contextes...","text":"<p>Le probl\u00e8me de notre approche est que les diff\u00e9rents sens, repr\u00e9sent\u00e9s par notre vecteur, ne prennent pas en compte la subtilit\u00e9 des diff\u00e9rents contextes. </p> <p>Par exemple, le mot avocat peut \u00eatre vu dans le contexte de la nourriture ou de la justice. Avec notre syst\u00e8me de type word2vec, notre repr\u00e9sentation du mot est unique. Elle ne change pas en fonction du contexte dans lequel il appara\u00eet. </p> <p>Une premi\u00e8re approche a consist\u00e9 \u00e0 ajouter au vecteur de base, d'autres vecteurs qui mat\u00e9rialisent d'autres contextes. Ainsi le vecteur initial se verra enrichi et affin\u00e9 en fonction d'autres contextes s\u00e9mantiques. </p> <p>Dans cette optique, le mot 'avocat' dans les phrases 'l'avocat a livr\u00e9 une plaidoirie au vitriol\" et \"la salade d'avocat \u00e9tait d\u00e9licieuse\", aura clairement des vecteurs de contextes diff\u00e9rents en plus de vecteurs repr\u00e9sentant la s\u00e9mantique de base du mot.</p> <p>Cette solution \u00e9tait obtenue en entra\u00eenant des r\u00e9seaux dits r\u00e9currents (RNN). Le but \u00e9tait de d\u00e9couvrir le mot suivant en fonction d'une s\u00e9quence pr\u00e9c\u00e9dente. Le langage a besoin de m\u00e9moire pour fonctionner efficacement. En effet, pour deviner un mot, il faut que je connaisse les mots pr\u00e9c\u00e9dents. Cette architecture permettait de m\u00e9moriser l'information. </p> <p>Bien qu'efficace, de nombreux probl\u00e8mes techniques rendait cette solution lente et difficile \u00e0 entra\u00eener. </p> <p>Face \u00e0 ce probl\u00e8me, des chercheurs ont propos\u00e9 une architecture qui allait r\u00e9volutionner le domaine : les Transformers. </p>"},{"location":"Notions_Essentielles/6_decoupage_des_mots_tokens/","title":"Le d\u00e9coupage des mots : les tokens","text":"<p>Les mod\u00e8les de langage consomment du texte en entr\u00e9e pour produire des sorties adapt\u00e9es aux t\u00e2ches prescrites. </p> <p>Pour utiliser le mod\u00e8le, il est n\u00e9cessaire de transformer les mots ou de proc\u00e9der \u00e0 un d\u00e9coupage \u00e9l\u00e9mentaire des documents. Ces op\u00e9rations, dites de tokenization, sont un classique du NLP et on trouve maints exemples en ligne. </p> <p>Toutefois, je reviens quelques instants sur la notion de tokenization car c'est un concept qui est utilis\u00e9 par GPT ou d'autres LLM notamment pour piloter la fen\u00eatre de tir - le nombre maximum de tokens en m\u00eame temps - et la grille de prix pay\u00e9 par l'utilisateur. </p>"},{"location":"Notions_Essentielles/6_decoupage_des_mots_tokens/#les-tokens-ne-correspondent-pas-exactement-aux-mots","title":"Les tokens ne correspondent pas exactement aux mots","text":"<p>Dans un mod\u00e8le comme word2vec, on s'est content\u00e9 d'isoler les mots un par un et de b\u00e2tir un vocabulaire. En NLP, la notion de token est plus large que celle de mots. C'est une unit\u00e9 \u00e9l\u00e9mentaire qui est utilis\u00e9 par un mod\u00e8le - un r\u00e9seau de neurones - pour apprendre une t\u00e2che. Il peut repr\u00e9senter un mot, une partie de mots, un caract\u00e8re unique, un signe de ponctuation, un caract\u00e8re sp\u00e9cial ou sp\u00e9cifique \u00e0 un mod\u00e8le, etc. D'ailleurs, dans la documentation d'openAI, il est indiqu\u00e9 qu'un token \u00e9quivaut, en anglais, \u00e0 0,75 mots.</p> <p>Un mod\u00e8le comme GPT consomme des tokens en entr\u00e9e. Cela signifie qu'il faut d'abord transformer vos donn\u00e9es en tokens avant leur utilisation par le mod\u00e8le. Les tokenizers modernes, comme ceux utilis\u00e9s par la famille GPT, permettent de ne pas avoir de mots qui ne seraient pas dans la vocabulaire car ils utilisent des sous-parties leur permettant de recomposer les mots inconnus qu'il pourrait voir hors des donn\u00e9es d'entra\u00eenement.</p>"},{"location":"Notions_Essentielles/6_decoupage_des_mots_tokens/#un-nombre-de-tokens-simultanes-limite","title":"Un nombre de tokens simultan\u00e9s limit\u00e9","text":"<p>Le nombre de tokens que le mod\u00e8le peut consommer en entr\u00e9e est limit\u00e9. Cela est vrai de tous les transformers qui traitent des s\u00e9quences de longueur fixe en entr\u00e9e. L'interface d'OpenAI fournit d'ailleurs un compteur de tokens. C'est \u00e9galement l'unit\u00e9 de mesure du prix factur\u00e9 qui est fond\u00e9 sur le nombre de tokens consomm\u00e9s \u00e0 chaque appel de l'API.</p> <p>Une fois la phrase tok\u00e9nis\u00e9e, le mod\u00e8le produit une donn\u00e9e de sortie qui correspond \u00e0 la probabilit\u00e9 qu'un mot soit le suivant de ceux d\u00e9j\u00e0 renseign\u00e9s. En r\u00e9alit\u00e9, il s'agit des probabilit\u00e9s distribu\u00e9es \u00e0 travers tous les tokens qui composent le vocabulaire du mod\u00e8le. On peut choisir la plus \u00e9lev\u00e9e mais \u00e9galement la plus rare. L'essentiel est que la g\u00e9n\u00e9ration reste coh\u00e9rente. </p> <p>Cette phase de sortie peut \u00eatre param\u00e9tr\u00e9e via l'interface d'openAI ou de la plupart des librairies. On peut notamment choisir le d\u00e9gr\u00e9 de cr\u00e9ativit\u00e9 du mod\u00e8le, c'est-\u00e0-dire sa capacit\u00e9 \u00e0 choisir des tokens tr\u00e8s fr\u00e9quents ou plus rares vus pendant la phase d'entra\u00eenement.</p>"},{"location":"Notions_Essentielles/6_decoupage_des_mots_tokens/#un-exemple-de-tokenisation","title":"Un exemple de tokenisation","text":"<p>Voici un exemple concret de tok\u00e9nization d'une phrase. Nous allons utiliser la librairie transformers du site Huggingface</p> <pre><code>from transformers import GPT2TokenizerFast\ntokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\ntokens = tokenizer('Une phrase de test en fran\u00e7ais')\nprint(\"La phrase repr\u00e9sent\u00e9 sous forme de r\u00e9f\u00e9rence des tokens\", tokens['input_ids'])\nprint(\"Voici le r\u00e9sulats de la phrase apr\u00e8s tokenisation pour ingestion par le mod\u00e8le GPT2 (anc\u00eatre de GPT3) : \", [tokenizer.decode(tok) for tok in tokens['input_ids']])\nLa phrase repr\u00e9sent\u00e9e sous forme de r\u00e9f\u00e9rence des tokens : \n[52, 710, 9546, 390, 1332, 551, 1216, 272, 16175, 15152] \nVoici le r\u00e9sulat de la phrase apr\u00e8s tokenisation pour ingestion par le mod\u00e8le GPT2 (anc\u00eatre de GPT3) : \n['U', 'ne', ' phrase', ' de', ' test', ' en', ' fr', 'an', '\u00e7', 'ais']\n</code></pre>"},{"location":"Notions_Essentielles/7_Transformers/","title":"Les Transformers","text":""},{"location":"Notions_Essentielles/7_Transformers/#lattention-est-tout-ce-quil-vous-faut","title":"L'Attention est tout ce qu'il vous faut","text":"<p>Les architectures de type transformers ont constitu\u00e9 une avanc\u00e9e tr\u00e8s importante en r\u00e9solvant notamment les probl\u00e8mes de m\u00e9moire. Cette architecture et ces nombreuses variantes dont le nom rappelle un jouet c\u00e9l\u00e8bre des ann\u00e9es 80 sont \u00e0 l'origine de GPT et de progr\u00e8s fulgurants dans le domaine.</p> <p>L'architecture des transformers utilise plusieurs m\u00e9canismes, parmi lesquels :</p> <ul> <li> <p>Un m\u00e9canisme d'attention, qui avait d\u00e9j\u00e0 \u00e9t\u00e9 conceptualis\u00e9 auparavant, permet aux mots d'une phrase d'apprendre l'importance des autres dans la m\u00eame phrase (self attention) ou dans une autre s\u00e9quence (attention) comme une phrase \u00e0 traduire. Comme indiqu\u00e9 dans l'article sur la repr\u00e9sentation des mots, ce m\u00e9canisme permet d'affiner les relations de pond\u00e9ration entre les mots donc de raffiner les contextes appris. </p> </li> <li> <p>Deux blocs :</p> <ul> <li> <p>encoder : il prend en entr\u00e9e une phrase d'une longueur variable et l'encode sous forme d'un vecteur de longueur fixe qui varie en fonction du contexte (principe du plongement lexical). Dans cette phase, le m\u00e9canisme d'attention se fait sur tous les mots de la phrase \u00e0 la fois : chaque mot peut 'regarder' tous les autres avant ou apr\u00e8s lui. Cette caract\u00e9ristique se retrouve dans le nom des encoder qui on comme prefix B pour Bidirectionnel. </p> </li> <li> <p>decoder : dans cette phase, chaque mot ne peut 'regarder' qu'en arri\u00e8re, les mots qui le suivent sont exclus du m\u00e9canisme d'attention. </p> </li> </ul> </li> </ul> <p>Ces blocs peuvent \u00eatre utilis\u00e9s s\u00e9parement ou ensemble (encoder-decoder ou sequence to sequence model). L'utilisation de ces diff\u00e9rentes parties ob\u00e9it \u00e0 des traitements particuliers : </p> Type T\u00e2ches Models Encoder Classification, reconnaissance d'entit\u00e9s nomm\u00e9es, analyse de sentiment, questions-r\u00e9ponses (extractive) BERT Decoder G\u00e9n\u00e9ration de s\u00e9quences de mots GPT x Sequence to sequence R\u00e9sum\u00e9, traduction, questions-r\u00e9ponses (g\u00e9n\u00e9ration) T5"},{"location":"Notions_Essentielles/7_Transformers/#lentrainement","title":"L'entra\u00eenement","text":"<p>Comme on l'a vu pour word2vec, les Transformers sont entra\u00een\u00e9s avec plusieurs approches :</p> <ul> <li>BERT : un mot (token) est masqu\u00e9 al\u00e9atoirement au milieu d'une phrase, il doit \u00eatre d\u00e9couvert. Le mod\u00e8le regarde avant et apr\u00e8s le token masqu\u00e9 (Encoder Bidirectionnel) ;</li> <li>GPT : le mot(token) suivant une s\u00e9quence doit \u00eatre d\u00e9couvert. Le mod\u00e8le ne regarde que la s\u00e9quence d'avant (Decoder Unidirectionnel).</li> </ul> <p>Cet entra\u00eenement de base, dont le principal objectif est d'apprendre la repr\u00e9sentation des mots,  peut \u00eatre poursuivi partiellement \u00e0 partir d'une couche suppl\u00e9mentaire comme indiqu\u00e9 dans l'article consacr\u00e9 \u00e0 l'entra\u00eenement des mod\u00e8les. </p>"},{"location":"Notions_Essentielles/8_Ontologie_Knowledge_Graph/","title":"Ontologie et Knowledge Graph","text":"<p>En informatique, une ontologie est un \"corpus structur\u00e9 de concepts, [qui est mod\u00e9lis\u00e9] dans un langage permettant l\u2019exploitation par un ordinateur des relations s\u00e9mantiques ou taxonomiques \u00e9tablies entre ces concepts\". Dit autrement, c'est une mani\u00e8re de structurer des connaissances en vue d'\u00eatre utilis\u00e9es par des machines.</p> <p>Les ontologies appartiennent \u00e0 la branche de l'IA dite symbolique qui a pour but de reproduire le raisonnement humain en le mod\u00e9lisant. Elles sont intensivement utilis\u00e9es en biologie, m\u00e9decine mais peu dans le domaine du droit. </p> <p>Les deux grands objectifs des ontologies sont : </p> <ul> <li>permettre la mise en \u0153uvre de raisonnements automatiques ;</li> <li>partager la connaissance en formalisant la repr\u00e9sentation de la connaissance.</li> </ul> <p>Sur le plan conceptuel, les ontologies reposent sur trois composants : </p> <ul> <li>les classes qui regroupent des concepts, des choses ou des objets ;</li> <li>les relations qui relient les classes entre elles ; </li> <li>les propri\u00e9t\u00e9s ou les caract\u00e9ristiques associ\u00e9es aux classes. </li> </ul> <p>On retrouve \u00e9galement ce concept dans une branche que l'on appelle le web s\u00e9mantique qui vise \u00e0 structurer les pages HTML  </p> <p>Pour illustrer ce concept, penchons-nous sur une ontologie conceptualisant le RGPD. </p>"},{"location":"Notions_Essentielles/8_Ontologie_Knowledge_Graph/#une-ontologie-du-rgpd","title":"Une ontologie du RGPD","text":"<p>Les ontologies ob\u00e9issent \u00e0 des principes mais la libert\u00e9 pr\u00e9vaut. Il n'existe pas une norme mais plusieurs approches, avec leur ressemblance, pour d\u00e9crire un domaine de connaissance. </p> <p>Les quelques paragraphes qui suivent sont inspir\u00e9s d'un papier intitul\u00e9 \"GDPRtEXT - GDPR as a Linked Data Resource\". </p> <p>Dans cette ontologie, on retrouve les textes juridiques d\u00e9coup\u00e9s en chapitres, sections, articles, points et sous-points qui permettent d'avoir une granularit\u00e9 fine et de mettre en \u00e9vidence les concepts qui sont d\u00e9finis par ces textes. </p> <p>Voici une visualisation de l'ontologie originale au format OWL via l'outil gratuit Prot\u00e9g\u00e9 : </p> <p></p> <p>On y aper\u00e7oit toute une s\u00e9rie de concepts : le consentement de la personne concern\u00e9e, les activit\u00e9s sur responsable de traitement, les exceptions ou les grands principes. Ces concepts sont organis\u00e9s hierarchiquement ou de mani\u00e8re transverse via une relation d'implication ('involves'). Ils sont rattach\u00e9s au texte via une relation nomm\u00e9e 'is defined by'. </p> <p>Ces liens font sens dans le cadre du RGPD et permettent de s'y retrouver dans un ensemble assez touffu. L'ontologie peut \u00eatre utilis\u00e9e pour servir de grille d'audit par exemple. Mais, pour aller plus loin, on peut int\u00e9grer cette ontologie dans une structure plus souple mais plus puissante : les Knowledge Graph.</p>"},{"location":"Notions_Essentielles/8_Ontologie_Knowledge_Graph/#un-exemple-dintegration-et-dutilisation-dans-neo4j","title":"Un exemple d'int\u00e9gration et d'utilisation dans neo4j","text":"<p>Le graph de connaissance (Knowledge Graph) est une mani\u00e8re souple de repr\u00e9senter les ontologies. Sa structure, sous forme de bin\u00f4me n\u0153ud/relation permet de coller aux sch\u00e9mas des ontologies. </p> <p>Cette forme de base de donn\u00e9es, associ\u00e9e \u00e0 des langages d'interrogation tr\u00e8s puissants comme SparQL ou Cipher, permet de nombreuses applications \u00e0 partir des ontologies et des donn\u00e9es associ\u00e9es.</p> <p>Les Knowledge Graph sont utilis\u00e9s dans des domaines tr\u00e8s vari\u00e9s et pr\u00e9sentent des caract\u00e9ristiques avantageuses parmi lesquelles :  - une tr\u00e8s grande libert\u00e9 dans l'organisation des donn\u00e9es ; - une grande simplicit\u00e9 puisqu'ils sont compos\u00e9s uniquement de n\u0153uds et de relations entre eux ; - une capacit\u00e9 \u00e0 \u00eatre utilis\u00e9s par de non-techniciens (le graph parle de lui-m\u00eame). </p> <p>Un exemple d'utilisation c\u00e9l\u00e8bre est l'investigation concernant les Panama Papers. Le graph a \u00e9t\u00e9 construit de mani\u00e8re automatique \u00e0 partir de millions de donn\u00e9es regroupant des emails, des pdf, des images et des bases de donn\u00e9es. A partir d'une structure n\u0153ud/relation simple, ressemblant \u00e0 celle que l'on trouve au Registre du Commerce et des Soci\u00e9t\u00e9s, un graph a \u00e9t\u00e9 construit avec le nom des soci\u00e9t\u00e9s, les mandataires, les actionnaires et des milliers d'informations contenues dans les donn\u00e9es ayant fuit\u00e9. </p> <p>En utilisant un langage permettant d'interroger le graph, il est possible d'obtenir des informations cach\u00e9es tr\u00e8s pertinentes comme remonter l'int\u00e9gralit\u00e9 des flux financiers, ou faire des corr\u00e9lations entre les pr\u00eate-noms. </p> <p>Revenons au RGPD. Sans pr\u00e9senter la volum\u00e9trie des * Panama Papers, c'est une l\u00e9gislation complexe et ramifi\u00e9e qui touche \u00e0 d'autres domaines comme la cybers\u00e9curit\u00e9. Il est possible de conceptualiser ce domaine avec un Knowledge Graph* et d'y appliquer des traitements complexes pour auditer des documents, g\u00e9n\u00e9rer des clauses, b\u00e2tir des outils de formation. </p> <p>Voici une illustration \u00e0 partir de quelques n\u0153uds extraits de la base RGPD dans AuraDB : </p> <p></p> <p>Cet outil poss\u00e8de un langage de requ\u00eates qui lui est propre (Cipher) et qui permet entre autres :   - de rapatrier toutes les relations entrantes et sortantes depuis un n\u0153ud ;  - de calculer la popularit\u00e9 (nombre de liens) d'un n\u0153ud ;  - de trier les relations selon leur sens, leur type... </p> <p>Ces r\u00e9sultats, coupl\u00e9s \u00e0 l'aide des outils de recherche s\u00e9mantique pour rapatrier les noms, peuvent fournir une aide pr\u00e9cieuse pour organiser les connaissances aux ramifications complexes. </p> <p>A ce stade, il faut une intervention humaine pour construire le graph et l'alimenter dans un premier temps. Il existe de nombreuses d\u00e9monstrations sur la cr\u00e9ation automatique de ce type de base de donn\u00e9es notamment en extrayant les relations entre entit\u00e9s. </p>"},{"location":"Notions_Essentielles/8_Ontologie_Knowledge_Graph/#la-creation-automatique-dontologies","title":"La cr\u00e9ation automatique d'ontologies","text":"<p>Cette exp\u00e9rience a \u00e9t\u00e9 men\u00e9e sur des d\u00e9cisions de justice am\u00e9ricaine avec le format json-ld \u00e0 l'aide de GPT 3.x.  Bien qu'imparfait, GPT a pu g\u00e9n\u00e9rer des fichiers dans un format structur\u00e9 \u00e0 partir des opinions de la Cour Supr\u00e8me des Etats-Unis. C'est un premier pas modeste vers une capacit\u00e9 \u00e0 raisonner. Le sujet est \u00e0 creuser notamment en droit fran\u00e7ais. </p> <p>la cr\u00e9ation automatique d'ontologies se heurte \u00e0 de nombreux obstacles parmi lesquels : </p> <ul> <li>l'ambiguit\u00e9 : un mot peut avoir plusieurs sens en fonction du contexte et \u00e9tablir un lien entre deux concepts peut se r\u00e9v\u00e9ler particuli\u00e8rement ardu ;</li> <li>le poids des concepts : la capacit\u00e9 humaine \u00e0 trier les choses importantes ou non n'est pas possible lors d'un traitement automatique. Dans le cas d'une ontologiee cr\u00e9\u00e9e automatiquement, il faut arriver \u00e0 trier ce qui est important dans le champ de connaissance et ce qui est accessoire. Cet objectif est tr\u00e8s difficile \u00e0 atteindre (voire impossible \u00e0 ce jour) ; </li> <li>la complexit\u00e9 des formulations : je vous laisse trouver des exemples dans les contrats ou les d\u00e9cisions de justice... </li> </ul> <p>Liens sur la g\u00e9n\u00e9ration de Graph \u00e0 partir de GPT :  - https://medium.com/neo4j/knowledge-graph-based-chatbot-with-gpt-3-and-neo4j-c4ebbd325ed - https://towardsdatascience.com/gpt-3-for-doctor-ai-1396d1cd6fa5 - https://www.topbots.com/guide-to-knowledge-graphs/ - https://pub.towardsai.net/automatic-knowledge-graphs-the-impossible-grail-ef71f9c8aad8</p>"},{"location":"Notions_Essentielles/9_GPT_art_prompting/","title":"L'art du prompting : un aper\u00e7u","text":"<p>Ce qu'il faut retenir</p> <ul> <li>le prompting est la mani\u00e8re de piloter les mod\u00e8les de langage comme GPT 3 pour obtenir des r\u00e9sultats pr\u00e9cis : Questions/R\u00e9ponses, raisonnement logique ou r\u00e9sum\u00e9</li> <li>il s'agit de textes r\u00e9dig\u00e9s en langage naturel dont les r\u00e8gles ne sont pas formellement \u00e9num\u00e9r\u00e9es</li> <li>il existe diff\u00e9rentes approches en fonction des objectifs \u00e0 remplir : de la formulation standard aux instructions \u00e9tape par \u00e9tape sophistiqu\u00e9es (Chain of Thought)</li> </ul> <p>L'objectif de ces quelques pages est de fournir une initiation au pilotage des nouveaux mod\u00e8les de langage comme ChatGPT. La force de ce type d'outil est de fournir une interface intuitive entre l'Homme et la machine. Il suffit de poser des questions en langage naturel pour avoir la r\u00e9ponse avec une fiabilit\u00e9 plus ou moins grande. </p> <p>En effet, ces mod\u00e8les de langage sont dit g\u00e9n\u00e9ratifs, c'est-\u00e0-dire qu'ils g\u00e9n\u00e9rent des mots appel\u00e9s tokens \u00e0 partir d'une s\u00e9quence connue. Cette s\u00e9quence est pr\u00e9cis\u00e9ment votre question. </p> <p>A partir de cette approche, on peut aller beaucoup plus loin dans la mani\u00e8re dont les humains peuvent int\u00e9ragir avec ces mod\u00e8les et leur faire ex\u00e9 uter des t\u00e2ches pr\u00e9cises comme un raisonnement logique, faire preuve de bon sens ou effectuer des op\u00e9rations d'arithm\u00e9tique. C'est pr\u00e9cis\u00e9ment cet ensemble de techniques que je vous propose de d\u00e9crire. </p> <p>L'objectif est de fournir un aper\u00e7u de cette (toute) nouvelle discipline passionnante qui fait l'objet de recherches intenses notamment par les \u00e9quipes de Google. Je reviendrai plus en d\u00e9tails dans des exemples concrets sur la fa\u00e7on dont le prompting peut \u00eatre utilis\u00e9 en mati\u00e8re juridique. </p>"},{"location":"Notions_Essentielles/9_GPT_art_prompting/#prompting","title":"Prompting  ?","text":"<p>En r\u00e9alit\u00e9, le prompting n'est rien d'autre qu'un bout de texte qui vise \u00e0 faire ex\u00e9cuter au mod\u00e8le une t\u00e2che pr\u00e9cise : r\u00e9diger un r\u00e9sum\u00e9, r\u00e9pondre \u00e0 une question ou traduire un texte. </p> <p>C'est une interface entre l'homme et le mod\u00e8le. Cette interface ne correspond pas \u00e0 un langage formalis\u00e9 comme du code informatique ou ce que l'on utilise sous Excel. </p> <p>Comme ces mod\u00e8les ont 'vu' pendant leur phase d'apprentissage un nombre consid\u00e9rable d'exemples, ils sont capables de se situer dans le contexte fourrni par la s\u00e9quence -  le prompt - renseign\u00e9 par l'utilisateur. Il utilise sa capacit\u00e9 \u00e0 reconna\u00eetre les patterns appris pour les r\u00e9pliquer dans la phase de completion qui vise \u00e0 g\u00e9n\u00e9rer les mots. Cette caract\u00e9ristique tr\u00e8s int\u00e9ressante fait qu'ils peuvent \u00eatre utilis\u00e9s pour remplir de nombreuses t\u00e2ches sans avoir besoin de les r\u00e9-entra\u00eener sur des jeux de donn\u00e9es sp\u00e9cifiques. </p> <p>Par exemple, le prompt suivant tr\u00e8s simple commande au mod\u00e8le de r\u00e9sumer un texte : </p> <p>Prompt standard pour r\u00e9sumer un texte</p> <p>R\u00e9sume moi en 100 mots le texte suivant : </p> <p>Texte : </p> <p>R\u00e9sum\u00e9 :</p> <p>On peut \u00e9galement lui fournir une liste d'exemples comme des questions/r\u00e9ponses et lui dire de continuer \u00e0 r\u00e9pondre selon ce sch\u00e9ma. Plus subtile, on peut introduire des instructions pour r\u00e9pondre \u00e0 la mani\u00e8re d'un math\u00e9maticien, d'une juriste, d'un enfant... </p>"},{"location":"Notions_Essentielles/9_GPT_art_prompting/#du-prompting-standard-a-la-chaine-de-pensees","title":"Du prompting standard \u00e0 la cha\u00eene de pens\u00e9es","text":"<p>La mani\u00e8re de s'adresser au mod\u00e8le a d'abord \u00e9t\u00e9 d'\u00eatre direct, \u00e0 l'instar de l'exemple pr\u00e9c\u00e9dent. ll suffit de lui demander sans forme ni d\u00e9tour le r\u00e9sultat qu'on souhaite, comme on le fait en demandant \u00e0 chatGPT de r\u00e9pondre \u00e0 une question. </p> <p>Rapidement, il est apparu que le prompting standard n'\u00e9tait pas efficace dans des op\u00e9rations de raisonnement logique, o\u00f9 il faut faire preuve de bon sens ou effectuer des op\u00e9rations d'arithm\u00e9tique. </p> <p>Fort de ce constat, un papier a propos\u00e9 une approche plus ambitieuse en fournissant, toujours via le prompt, les \u00e9tapes que le mod\u00e8le doit accomplir pour aboutir au r\u00e9sultat final. Cette approche est appel\u00e9e 'Chain of Thought Prompting'</p> <p></p> <p>Dans cette approche, on a toujours une structure g\u00e9n\u00e9rale de quelques exemples de Questions/R\u00e9ponses mais on explicite dans la r\u00e9ponse le chemin \u00e0 parcourir pour obtenir la solution. Cette strat\u00e9gie obtient de tr\u00e8s bons r\u00e9sultats mais elle n'est efficace que sur les mod\u00e8les de langage avec de nombreux param\u00e8tres (sup\u00e9rieurs \u00e0 100 millards). </p> <p>Il existe plusieurs raffinements concernant cette strat\u00e9gie : </p> <ul> <li>Zero Shot Chain of Thought : l'id\u00e9e est de faire cr\u00e9er par le mod\u00e8le lui-m\u00eame les \u00e9tapes du raisonnement avec la commande ('Raisonne \u00e9tape par \u00e9tape') puis d'injecter la r\u00e9ponse fournie \u00e0 la suite du probl\u00e8me pour atteindre le r\u00e9sultat. On ne fournit rien au mod\u00e8le comme exemple (\"zero shot\") et il \u00e9labore lui-m\u00eame son raisonnement. G\u00e9nial, non ? On verra que cette propri\u00e9t\u00e9 est utilis\u00e9e et syst\u00e9matis\u00e9e dans certains frameworks comme  Demonstrate Search Predict. </li> <li>Self-Consistency  ou auto-consistance : cette technique consiste \u00e0 g\u00e9n\u00e9rer plusieurs cha\u00eenes d'instructions pour un m\u00eame probl\u00e8me puis \u00e0 retenir la solution qui revient la plus fr\u00e9quemment. </li> </ul>"},{"location":"Notions_Essentielles/9_GPT_art_prompting/#quelques-regles-pour-rediger-de-bons-prompts","title":"Quelques r\u00e9gles pour r\u00e9diger de bons prompts","text":"<p>Il ne faut pas perdre de vue que l'histoire du prompting n'a que quelques mois. Les progr\u00e8s dans le domaine du traitement automatique du langage ont \u00e9t\u00e9 tellement rapides que ces quelques lignes sont s\u00fbrement d\u00e9j\u00e0 obsol\u00e8tes. </p> <p>Toujours est-il qu'il existe quelques r\u00e8gles, parfois contre-intuitives, concernant l'efficacit\u00e9 de la r\u00e9daction d'un prompt : </p> <ul> <li>le fait de donner une bonne r\u00e9ponse dans les exemples fournis n'est pas significatif sur la performance obtenue par le mod\u00e8le. Autrement dit, il apprend du pattern et non de la v\u00e9racit\u00e9 de ce qui lui est fourni ; </li> <li>le format est tr\u00e8s important. Il commande la mani\u00e8re dont le mod\u00e8le va g\u00e9n\u00e9rer la r\u00e9ponse par exemple sous forme de liste s\u00e9par\u00e9e par des virgules ou en majuscule ;</li> <li>le nombre d'exemples optimal est souvent de 4 \u00e0 8.</li> </ul>"},{"location":"Notions_Essentielles/9_GPT_art_prompting/#exemples-de-prompts-courants","title":"Exemples de prompts courants","text":""},{"location":"Notions_Essentielles/9_GPT_art_prompting/#prompts-standards","title":"Prompts standards  :","text":""},{"location":"Notions_Essentielles/9_GPT_art_prompting/#chain-of-thought","title":"Chain of Thought","text":"<p>Dans cet exemple, GPT (davinci 003) se trompe et n'arrive pas \u00e0 \"raisonner\" pour trouver la bonne r\u00e9ponse. </p> <p></p> <p>On raffine le prompt en ajoutant : </p> <ul> <li>la mani\u00e8re de calculer les deux trajets ; </li> <li>un ou plusieurs exemples (few shots CoT) pour lui montrer le type de raisonnement. </li> </ul> <p>Dans ce cas, il arrive au bon r\u00e9sultat en explicitant les \u00e9tapes de son raisonnement. </p> <p></p> <p>Il est possible, pour se passer de lui d\u00e9crire quelques exemples, d'introduire un prompt \"magique\" du type \" D\u00e9cris-moi les \u00e9tapes de ton raisonnement \". On parlera de zeroshot Chain Of Thought. </p> <p></p> <p>Liens : </p> <ul> <li>Learning Prompt</li> <li>Prompting GPT-3 To Be Reliable</li> <li>https://www.outilsfroids.net/2023/02/vous-dorkiez-jen-suis-fort-aise-et-bien-promptez-maintenant/</li> <li>Language Models are Few-Shot Learners</li> </ul>"},{"location":"Projets/audit_contrat/","title":"Pr\u00e9-audit de contrat","text":""},{"location":"Ressources/Papiers%20de%20recherche/","title":"Papiers de recherche","text":"<p>Je ne reprend ici que les papiers de recherche r\u00e9cents sp\u00e9cifiques au NLP et au droit.  La s\u00e9lection n'est \u00e9videmment pas exhaustive et r\u00e9fl\u00e8te mes centres d'int\u00e9r\u00eat (droit europ\u00e9en et continental, reasoning, graph, classification ...)</p>"},{"location":"Ressources/Papiers%20de%20recherche/#language-model-juridique","title":"Language Model (Juridique)","text":"<p>Pour une liste des mod\u00e8les g\u00e9n\u00e9ralistes : [[LLM_Liste]]</p>"},{"location":"Ressources/Papiers%20de%20recherche/#juribert-a-masked-language-model-adaptation-for-french-legal-text","title":"JuriBERT: A Masked-Language Model Adaptation for French Legal Text","text":"<p>https://arxiv.org/abs/2110.01485 Abstract Language models have proven to be very useful when adapted to specific domains. Nonetheless, little research has been done on the adaptation of domain-specific BERT models in the French language. In this paper, we focus on creating a language model adapted to French legal text with the goal of helping law professionals. We conclude that some specific tasks do not benefit from generic language models pre-trained on large amounts of data. We explore the use of smaller architectures in domain-specific sub-languages and their benefits for French legal text. We prove that domain-specific pre-trained models can perform better than their equivalent generalised ones in the legal domain. Finally, we release JuriBERT, a new set of BERT models adapted to the French legal domain.</p>"},{"location":"Ressources/Papiers%20de%20recherche/#legal-bert-the-muppets-straight-out-of-law-school","title":"LEGAL-BERT: The Muppets straight out of Law School","text":"<p>https://aclanthology.org/2020.findings-emnlp.261.pdf Abstract BERT has achieved impressive performance in several NLP tasks. However, there has been limited investigation on its adaptation guidelines in specialised domains. Here we focus on the legal domain, where we explore several approaches for applying BERT models to downstream legal tasks, evaluating on multiple datasets. Our findings indicate that the previous guidelines for pre-training and fine-tuning, often blindly followed, do not always generalize well in the legal domain. Thus we propose a systematic investigation of the available strategies when applying BERT in specialised domains. These are: (a) use the original BERT out of the box, (b) adapt BERT by additional pre-training on domain-specific corpora, and (c) pre-train BERT from scratch on domain-specific corpora. We also propose a broader hyper-parameter search space when fine-tuning for downstream tasks and we release LEGAL-BERT, a family of BERT models intended to assist legal NLP research, computational law, and legal technology applications.</p>"},{"location":"Ressources/Papiers%20de%20recherche/#legaldb-long-distilbert-for-legal-document-classification","title":"LegalDB: Long DistilBERT for Legal Document Classification","text":"<p>https://ieeexplore.ieee.org/document/9392558 Abstract Transformers have caused a paradigm shift in tasks related to natural language. From text summarization to classification, these models have established new state-of-the-art results on various general and closed domain tasks. Having said that, most of the popular transformer based models (BERT - Bidirectional Encoder Representations from Transformers, DistilBERT, and RoBERTa) face a limitation in terms of the content length they can accept. This is because the self-attention used by these models scales quadratically with the context sequence length. While this works well for short passages and questions, for longer documents this method fails to effectively capture both the local and global contexts. This shortcoming is underscored further for closed domain tasks like Legal Document classification, where the length of the documents can extend up to a couple of pages and which differ in their vocabulary from general English substantially. In this paper, a new architecture is proposed, where the concept of \"long\" attention is applied to a distilled BERT and then the model is pre-trained on legal-domain specific corpora. This helps combine a local windowed attention with task-motivated global attention, making the model contextually-aware for longer sequences. The proposed model is also able to outperform fine-tuned BERT and other transformer-based models at the task of legal document classification while also being faster.</p>"},{"location":"Ressources/Papiers%20de%20recherche/#generalites","title":"G\u00e9n\u00e9ralit\u00e9s","text":""},{"location":"Ressources/Papiers%20de%20recherche/#how-does-nlp-benefit-legal-system-a-summary-of-legal-artificial-intelligence","title":"How Does NLP Benefit Legal System: A Summary of Legal Artificial Intelligence","text":"<p>https://arxiv.org/pdf/2004.12158.pdf Abstract Legal Artificial Intelligence (LegalAI) focuses on applying the technology of artificial intelligence, especially natural language processing,to benefit tasks in the legal domain. In recent years, LegalAI has drawn increasing attention rapidly from both AI researchers and legal professionals, as LegalAI is beneficial to the legal system for liberating legal professionals from a maze of paperwork. Legal professionals often think about how to solve tasks from rulebased and symbol-based methods, while NLP researchers concentrate more on data-driven and embedding methods. In this paper, we describe the history, the current state, and the future directions of research in LegalAI. We illustrate the tasks from the perspectives of legal professionals and NLP researchers and show several representative applications in LegalAI. We conduct experiments and provide an indepth analysis of the advantages and disadvantages of existing works to explore possible future directions. You can find the implementation of our work from https://github. com/thunlp/CLAIM.</p>"},{"location":"Ressources/Papiers%20de%20recherche/#prompting-legal-prompting","title":"Prompting - Legal Prompting","text":""},{"location":"Ressources/Papiers%20de%20recherche/#legal-prompting-teaching-a-language-model-to-think-like-a-lawyer","title":"Legal Prompting: Teaching a Language Model to Think Like a Lawyer","text":"<p>https://arxiv.org/abs/2212.01326</p> <p>Abstract :  Large language models that are capable of zero or few-shot prompting approaches have given rise to the new research area of prompt engineering. Recent advances showed that for example Chain-of-Thought (CoT) prompts can improve arithmetic or common sense tasks significantly. We explore how such approaches fare with legal reasoning tasks and take the COLIEE entailment task based on the Japanese Bar exam for testing zero-shot/few-shot and fine-tuning approaches. Our findings show that while CoT prompting and fine-tuning with explanations approaches show improvements, the best results are produced by prompts that are derived from specific legal reasoning techniques such as IRAC (Issue, Rule, Application, Conclusion). Based on our experiments we improve the 2021 best result from 0.7037 accuracy to 0.8148 accuracy and beat the 2022 best system of 0.6789 accuracy with an accuracy of 0.7431.</p>"},{"location":"Ressources/Papiers%20de%20recherche/#legal-prompt-engineering-for-multilingual-legal-judgement-prediction","title":"Legal Prompt Engineering for Multilingual Legal Judgement Prediction","text":"<p>https://arxiv.org/pdf/2212.02199v1.pdf Abstract (traduction FR auto) Le Legal Prompt Engineering (LPE) ou Legal Prompting est un processus visant \u00e0 guider et \u00e0 assister un mod\u00e8le de langage large (LLM) pour effectuer un traitement du langage juridique naturel (NLLP) comp\u00e9tence. Notre objectif est d'utiliser le LPE avec des LLM sur documents juridiques longs pour le Legal Judgement pr\u00e9diction (LJP). Nous \u00e9tudions la performance du LPE pour des faits donn\u00e9s dans des textes de cas provenant de la Cour Europ\u00e9enne de Justice dans des textes de cas de la Cour Europ\u00e9enne des Droits de l'Homme (en anglais) europ\u00e9enne des droits de l'homme (en anglais) et du Tribunal f\u00e9d\u00e9ral f\u00e9d\u00e9rale de Suisse (en allemand, fran\u00e7ais et italien). italien). Nos r\u00e9sultats montrent que le LPE est meilleur par rapport aux lignes de base, mais qu'il n'est toujours pas \u00e0 la hauteur de l'\u00e9tat actuel de l'art rn '\u00e9tat actuel de l'art des approches supervis\u00e9es. approches supervis\u00e9es. N\u00e9anmoins, les r\u00e9sultats sont importants, car 1) aucune donn\u00e9e explicite sp\u00e9cifique au domaine n'a \u00e9t\u00e9 utilis\u00e9e - nous montrons donc que le transfert au domaine juridique est possible pour les approches LL g\u00e9n\u00e9rales. Nous montrons donc que le transfert vers le domaine juridique est possible pour les MLL \u00e0 usage g\u00e9n\u00e9ral. Les LLMs ont \u00e9t\u00e9 directement appliqu\u00e9s sans aucune formation ou r\u00e9glage fin suppl\u00e9mentaire - ce qui ce qui permet de r\u00e9aliser des \u00e9conomies consid\u00e9rables en termes de co\u00fbts de calcul suppl\u00e9mentaires.</p>"},{"location":"Ressources/Papiers%20de%20recherche/#active-prompting-with-chain-of-thought-for-large-language-models","title":"Active Prompting with Chain-of-Thought for Large Language Models","text":"<p>https://arxiv.org/pdf/2302.12246 Abstract The increasing scale of large language models (LLMs) brings emergent abilities to various complex tasks requiring reasoning, such as arithmetic and commonsense reasoning. It is known that the effective design of task-specific prompts is critical for LLMs' ability to produce high-quality answers. In particular, an effective approach for complex question-and-answer tasks is example-based prompting with chain-of-thought (CoT) reasoning, which significantly improves the performance of LLMs. However, current CoT methods rely on a fixed set of human-annotated exemplars, which are not necessarily the most effective examples for different tasks. This paper proposes a new method, Active-Prompt, to adapt LLMs to different tasks with task-specific example prompts (annotated with human-designed CoT reasoning). For this purpose, we propose a solution to the key problem of determining which questions are the most important and helpful ones to annotate from a pool of task-specific queries. By borrowing ideas from the related problem of uncertainty-based active learning, we introduce several metrics to characterize the uncertainty so as to select the most uncertain questions for annotation. Experimental results demonstrate the superiority of our proposed method, achieving state-of-the-art on eight complex reasoning tasks. Further analyses of different uncertainty metrics, pool sizes, zero-shot learning, and accuracy-uncertainty relationship demonstrate the effectiveness of our method. </p>"},{"location":"Ressources/Papiers%20de%20recherche/#more-than-youve-asked-for-a-comprehensive-analysis-of-novel-prompt-injection-threats-to-application-integrated-large-language-models","title":"More than you've asked for: A Comprehensive Analysis of Novel Prompt Injection Threats to Application-Integrated Large Language Models","text":"<p>https://arxiv.org/pdf/2302.12173 Abstract We are currently witnessing dramatic advances in the capabilities of Large Language Models (LLMs). They are already being adopted in practice and integrated into many systems, including integrated development environments (IDEs) and search engines. The functionalities of current LLMs can be modulated via natural language prompts, while their exact internal functionality remains implicit and unassessable. This property, which makes them adaptable to even unseen tasks, might also make them susceptible to targeted adversarial prompting. Recently, several ways to misalign LLMs using Prompt Injection (PI) attacks have been introduced. In such attacks, an adversary can prompt the LLM to produce malicious content or override the original instructions and the employed filtering schemes. Recent work showed that these attacks are hard to mitigate, as state-of-the-art LLMs are instruction-following. So far, these attacks assumed that the adversary is directly prompting the LLM. In this work, we show that augmenting LLMs with retrieval and API calling capabilities (so-called Application-Integrated LLMs) induces a whole new set of attack vectors. These LLMs might process poisoned content retrieved from the Web that contains malicious prompts pre-injected and selected by adversaries. We demonstrate that an attacker can indirectly perform such PI attacks. Based on this key insight, we systematically analyze the resulting threat landscape of Application-Integrated LLMs and discuss a variety of new attack vectors. To demonstrate the practical viability of our attacks, we implemented specific demonstrations of the proposed attacks within synthetic applications. In summary, our work calls for an urgent evaluation of current mitigation techniques and an investigation of whether new techniques are needed to defend LLMs against these threats.</p>"},{"location":"Ressources/Papiers%20de%20recherche/#questionsreponses-qa","title":"Questions/R\u00e9ponses (Q&amp;A)","text":""},{"location":"Ressources/Papiers%20de%20recherche/#question-answering-for-privacy-policies-combining-computational-and-legal-perspectives","title":"Question Answering for Privacy Policies: Combining Computational and Legal Perspectives","text":"<p>https://arxiv.org/pdf/1911.00841.pdf Abstract Privacy policies are long and complex documents that are difficult for users to read and understand, and yet, they have legal effects on how user data is collected, managed and used. Ideally, we would like to empower users to inform themselves about issues that matter to them, and enable them to selective explore those issues. We present PRIVACYQA, a corpus consisting of 1750 questions about the privacy policies of mobile applications, and over 3500 expert annotations of relevant answers. We observe that a strong neural baseline underperforms human performance by almost 0.3 F1 on PRIVACYQA, suggesting considerable room for improvement for future systems. Further, we use this dataset to shed light on challenges to question answerability, with domain-general implications for any question answering system. The PRIVACYQA corpus offers a challenging corpus for question answering, with genuine real-world utility</p>"},{"location":"Ressources/Papiers%20de%20recherche/#zerofew-shots-learning","title":"Zero/Few Shots Learning","text":""},{"location":"Ressources/Papiers%20de%20recherche/#billions-of-parameters-are-worth-more-than-in-domain-training-data-a-case-study-in-the-legal-case-entailment-task","title":"Billions of Parameters Are Worth More Than In-domain Training Data: A case study in the Legal Case Entailment Task","text":"<p>https://arxiv.org/pdf/2205.15172.pdf Abstract Recent work has shown that language models scaled to billions of parameters, such as GPT-3, perform remarkably well in zeroshot and few-shot scenarios. In this work, we experiment with zero-shot models in the legal case entailment task of the COLIEE 2022 competition. Our experiments show that scaling the number of parameters in a language model improves the F1 score of our previous zeroshot result by more than 6 points, suggesting that stronger zero-shot capability may be a characteristic of larger models, at least for this task. Our 3B-parameter zero-shot model outperforms all models, including ensembles, in the COLIEE 2021 test set and also achieves the best performance of a single model in the COLIEE 2022 competition, second only to the ensemble composed of the 3B model itself and a smaller version of the same model. Despite the challenges posed by large language models, mainly due to latency constraints in real-time applications, we provide a demonstration of our zero-shot monoT5-3b model being used in production as a search engine, including for legal documents. The code for our submission and the demo of our system are available at https://github.com/neuralmind-ai/coliee and https://neuralsearchx.neuralmind.ai, respectively.</p>"},{"location":"Ressources/Papiers%20de%20recherche/#clause-generation-clausier","title":"Clause generation (clausier)","text":""},{"location":"Ressources/Papiers%20de%20recherche/#graph-based-keyword-planning-for-legal-clause-generation-from-topics","title":"Graph-based Keyword Planning for Legal Clause Generation from Topics","text":"<p>https://arxiv.org/pdf/2301.06901.pdf Abstract Generating domain-specific content such as legal clauses based on minimal user-provided information can be of significant benefit in automating legal contract generation. In this paper, we propose a controllable graph-based mechanism that can generate legal clauses using only the topic or type of the legal clauses. Our pipeline consists of two stages involving a graph-based planner followed by a clause generator. The planner outlines the content of a legal clause as a sequence of keywords in the order of generic to more specific clause information based on the input topic using a controllable graph-based mechanism. The generation stage takes in a given plan and generates a clause. The pipeline consists of a graph-based planner followed by text generation. We illustrate the effectiveness of our proposed twostage approach on a broad set of clause topics in contracts.</p>"},{"location":"Ressources/Papiers%20de%20recherche/#nli-inference","title":"NLI (inf\u00e9rence)","text":""},{"location":"Ressources/Papiers%20de%20recherche/#contractnli-a-dataset-for-document-level-natural-language-inference-for-contracts","title":"ContractNLI: A Dataset for Document-level Natural Language Inference for Contracts","text":"<p>https://aclanthology.org/2021.findings-emnlp.164.pdf Abstract Reviewing contracts is a time-consuming procedure that incurs large expenses to companies and social inequality to those who cannot afford it. In this work, we propose \u201cdocument-level natural language inference (NLI) for contracts\u201d, a novel, real-world application of NLI that addresses such problems. In this task, a system is given a set of hypotheses (such as \u201cSome obligations of Agreement may survive termination.\u201d) and a contract, and it is asked to classify whether each hypothesis is \u201centailed by\u201d, \u201ccontradicting to\u201d or \u201cnot mentioned by\u201d (neutral to) the contract as well as identifying \u201cevidence\u201d for the decision as spans in the contract. We annotated and release the largest corpus to date consisting of 607 annotated contracts. We then show that existing models fail badly on our task and introduce a strong baseline, which (a) models evidence identification as multi-label classification over spans instead of trying to predict start and end tokens, and (b) employs more sophisticated context segmentation for dealing with long documents. We also show that linguistic characteristics of contracts, such as negations by exceptions, are contributing to the difficulty of this task and that there is much room for improvement.</p>"},{"location":"Ressources/Papiers%20de%20recherche/#validity-assessment-of-legal-will-statements","title":"Validity Assessment of Legal Will Statements","text":"<p>as Natural Language Inference https://arxiv.org/pdf/2210.16989.pdf Abstract This work introduces a natural language inference (NLI) dataset that focuses on the validity of statements in legal wills. This dataset is unique because: (a) each entailment decision requires three inputs: the statement from the will, the law, and the conditions that hold at the time of the testator\u2019s death; and (b) the included texts are longer than the ones in current NLI datasets. We trained eight neural NLI models in this dataset. All the models achieve more than 80% macro F1 and accuracy, which indicates that neural approaches can handle this task reasonably well. However, group accuracy, a stricter evaluation measure that is calculated with a group of positive and negative examples generated from the same statement as a unit, is in mid 80s at best, which suggests that the models\u2019 understanding of the task remains superficial. Further ablative analyses and explanation experiments indicate that all three text segments are used for prediction, but some decisions rely on semantically irrelevant tokens. This indicates that overfitting on these longer texts likely happens, and that additional research is required for this task to be solved.</p>"},{"location":"Ressources/Papiers%20de%20recherche/#resume-automatique","title":"R\u00e9sum\u00e9  automatique","text":""},{"location":"Ressources/Papiers%20de%20recherche/#incorporating-domain-knowledge-for-extractive-summarization-of-legal-case-documents","title":"Incorporating Domain Knowledge for Extractive Summarization of Legal Case Documents","text":"<p>https://arxiv.org/pdf/2106.15876.pdf Abstract Automatic summarization of legal case documents is an important and practical challenge. Apart from many domain-independent text summarization algorithms that can be used for this purpose, several algorithms have been developed specifically for summarizing legal case documents. However, most of the existing algorithms do not systematically incorporate domain knowledge that specifies what information should ideally be present in a legal case document summary. To address this gap, we propose an unsupervised summarization algorithm DELSumm which is designed to systematically incorporate guidelines from legal experts into an optimization setup. We conduct detailed experiments over case documents from the Indian Supreme Court. The experiments show that our proposed unsupervised method outperforms several strong baselines in terms of ROUGE scores, including both general summarization algorithms and legal-specific ones. In fact, though our proposed algorithm is unsupervised, it outperforms several supervised summarization models that are trained over thousands of document-summary pairs.</p>"},{"location":"Ressources/Papiers%20de%20recherche/#arglegalsumm-improving-abstractive-summarization-of-legal","title":"ArgLegalSumm: Improving Abstractive Summarization of Legal","text":"<p>Documents with Argument Mining https://arxiv.org/pdf/2209.01650.pdf Abstract A challenging task when generating summaries of legal documents is the ability to address their argumentative nature. We introduce a simple technique to capture the argumentative structure of legal documents by integrating argument role labeling into the summarization process. Experiments with pretrained language models show that our proposed approach improves performance over strong baselines.</p>"},{"location":"Ressources/Papiers%20de%20recherche/#eur-lex-sum-a-multi-and-cross-lingual-dataset-for-long-form-summarization-in-the-legal-domain","title":"EUR-Lex-Sum: A Multi- and Cross-lingual Dataset for Long-form Summarization in the Legal Domain","text":"<p>https://arxiv.org/pdf/2210.13448.pdf Abstract Existing summarization datasets come with two main drawbacks: (1) They tend to focus on overly exposed domains, such as news articles or wiki-like texts, and (2) are primarily monolingual, with few multilingual datasets. In this work, we propose a novel dataset, called EUR-Lex-Sum, based on manually curated document summaries of legal acts from the European Union law platform (EUR-Lex). Documents and their respective summaries exist as cross-lingual paragraph-aligned data in several of the 24 official European languages, enabling access to various cross-lingual and lower-resourced summarization setups. We obtain up to 1,500 document/summary pairs per language, including a subset of 375 crosslingually aligned legal acts with texts available in all 24 languages. In this work, the data acquisition process is detailed and key characteristics of the resource are compared to existing summarization resources. In particular, we illustrate challenging sub-problems and open questions on the dataset that could help the facilitation of future research in the direction of domain-specific cross-lingual summarization. Limited by the extreme length and language diversity of samples, we further conduct experiments with suitable extractive monolingual and cross-lingual baselines for future work. Code for the extraction as well as access to our data and baselines is available online at: https://github.com/ achouhan93/eur-lex-sum.</p>"},{"location":"Ressources/Papiers%20de%20recherche/#an-evaluation-framework-for-legal-document-summarization","title":"An Evaluation Framework for Legal Document Summarization","text":"<p>https://arxiv.org/pdf/2205.08478.pdf Abstract A law practitioner has to go through numerous lengthy legal case proceedings for their practices of various categories, such as land dispute, corruption, etc. Hence, it is important to summarize these documents, and ensure that summaries contain phrases with intent matching the category of the case. To the best of our knowledge, there is no evaluation metric that evaluates a summary based on its intent. We propose an automated intent-based summarization metric, which shows a better agreement with human evaluation as compared to other automated metrics like BLEU, ROUGE-L etc. in terms of human satisfaction. We also curate a dataset by annotating intent phrases in legal documents, and show a proof of concept as to how this system can be automated. Additionally, all the code and data to generate reproducible results is available on Github.</p>"},{"location":"Ressources/Papiers%20de%20recherche/#legal-case-document-summarization-extractive-and-abstractive-methods-and-their-evaluation","title":"Legal Case Document Summarization: Extractive and Abstractive Methods and their Evaluation","text":"<p>https://arxiv.org/pdf/2210.07544.pdf Abstract Summarization of legal case judgement documents is a challenging problem in Legal NLP. However, not much analyses exist on how different families of summarization models (e.g., extractive vs. abstractive) perform when applied to legal case documents. This question is particularly important since many recent transformer-based abstractive summarization models have restrictions on the number of input tokens, and legal documents are known to be very long. Also, it is an open question on how best to evaluate legal case document summarization systems. In this paper, we carry out extensive experiments with several extractive and abstractive summarization methods (both supervised and unsupervised) over three legal summarization datasets that we have developed. Our analyses, that includes evaluation by law practitioners, lead to several interesting insights on legal summarization in specific and long document summarization in general.</p>"},{"location":"Ressources/Papiers%20de%20recherche/#transfert-learning","title":"Transfert learning","text":""},{"location":"Ressources/Papiers%20de%20recherche/#an-empirical-study-on-cross-x-transfer-for-_lega_l-judgment-prediction","title":"An Empirical Study on Cross-X Transfer for\u00a0_Lega_l Judgment Prediction","text":"<p>https://arxiv.org/pdf/2209.12325.pdf  Abstract Cross-lingual transfer learning has proven useful in a variety of Natural Language Processing (NLP) tasks, but it is understudied in the context of legal NLP, and not at all in Legal Judgment Prediction (LJP). We explore transfer learning techniques on LJP using the trilingual Swiss-Judgment-Prediction dataset, including cases written in three languages. We find that cross-lingual transfer improves the overall results across languages, especially when we use adapter-based fine-tuning. Finally, we further improve the model\u2019s performance by augmenting the training dataset with machine-translated versions of the original documents, using a 3\u00d7 larger training corpus. Further on, we perform an analysis exploring the effect of cross-domain and crossregional transfer, i.e., train a model across domains (legal areas), or regions. We find that in both settings (legal areas, origin regions), models trained across all groups perform overall better, while they also have improved results in the worst-case scenarios. Finally, we report improved results when we ambitiously apply cross-jurisdiction transfer, where we further augment our dataset with Indian legal cases</p>"},{"location":"Ressources/Papiers%20de%20recherche/#recommender-system","title":"Recommender system","text":""},{"location":"Ressources/Papiers%20de%20recherche/#evaluating-document-representations-for-content-based-legal-literature-recommendations","title":"Evaluating Document Representations for Content-based Legal Literature Recommendations","text":"<p>https://arxiv.org/pdf/2104.13841.pdf</p> <p>Abstract Recommender systems assist legal professionals in finding relevant literature for supporting their case. Despite its importance for the profession, legal applications do not reflect the latest advances in recommender systems and representation learning research. Simultaneously, legal recommender systems are typically evaluated in small-scale user study without any public available benchmark datasets. Thus, these studies have limited reproducibility. To address the gap between research and practice, we explore a set of state-ofthe-art document representation methods for the task of retrieving semantically related US case law. We evaluate text-based (e.g., fastText, Transformers), citation-based (e.g., DeepWalk, Poincar\u00e9), and hybrid methods. We compare in total 27 methods using two silver standards with annotations for 2,964 documents. The silver standards are newly created from Open Case Book and Wikisource and can be reused under an open license facilitating reproducibility. Our experiments show that document representations from averaged fastText word vectors (trained on legal corpora) yield the best results, closely followed by Poincar\u00e9 citation embeddings. Combining fastText and Poincar\u00e9 in a hybrid manner further improves the overall result. Besides the overall performance, we analyze the methods depending on document length, citation count, and the coverage of their recommendations. We make our source code, models, and datasets publicly available.</p>"},{"location":"Ressources/Papiers%20de%20recherche/#raisonnement-juridique","title":"Raisonnement juridique","text":""},{"location":"Ressources/Papiers%20de%20recherche/#finding-the-law-enhancing-statutory-article-retrieval-via-graph-neural-networks","title":"Finding the Law: Enhancing Statutory Article Retrieval via Graph Neural Networks","text":"<p>https://arxiv.org/pdf/2301.12847.pdf Abstract Statutory article retrieval (SAR), the task of retrieving statute law articles relevant to a legal question, is a promising application of legal text processing. In particular, high-quality SAR systems can improve the work efficiency of legal professionals and provide basic legal assistance to citizens in need at no cost. Unlike traditional ad-hoc information retrieval, where each document is considered a complete source of information, SAR deals with texts whose full sense depends on complementary information from the topological organization of statute law. While existing works ignore these domain-specific dependencies, we propose a novel graph-augmented dense statute retriever (G-DSR) model that incorporates the structure of legislation via a graph neural network to improve dense retrieval performance. Experimental results show that our approach outperforms strong retrieval baselines on a real-world expert-annotated SAR dataset.1</p>"},{"location":"Ressources/Papiers%20de%20recherche/#text-guided-legal-knowledge-graph-reasoning","title":"Text-guided Legal Knowledge Graph Reasoning","text":"<p>https://arxiv.org/pdf/2104.02284.pdf Abstract Recent years have witnessed the prosperity of legal artificial intelligence with the development of technologies. In this paper, we propose a novel legal application of legal provision prediction (LPP), which aims to predict the related legal provisions of affairs. We formulate this task as a challenging knowledge graph completion problem, which requires not only text understanding but also graph reasoning. To this end, we propose a novel text-guided graph reasoning approach. We collect amounts of real-world legal provision data from the Guangdong government service website and construct a legal dataset called LegalLPP. Extensive experimental results on the dataset show that our approach achieves better performance compared with baselines. The code and dataset are available in https://github.com/zxlzr/LegalPP for reproducibility.</p>"},{"location":"Ressources/Papiers%20de%20recherche/#can-gpt-3-perform-statutory-reasoning","title":"Can GPT-3 Perform Statutory Reasoning?","text":"<p>https://arxiv.org/pdf/2302.06100.pdf Abstract Statutory reasoning is the task of reasoning with facts and statutes, which are rules written in natural language by a legislature. It is a basic legal skill. In this paper we explore the capabilities of the most capable GPT-3 model, text-davinci-003, on an established statutory-reasoning dataset called SARA. We consider a variety of approaches, including dynamic few-shot prompting, chain-ofthought prompting, and zero-shot prompting. While we achieve results with GPT-3 that are better than the previous best published results, we also identify several types of clear errors it makes. In investigating why these happen, we discover that GPT-3 has imperfect prior knowledge of the actual U.S. statutes on which SARA is based. More importantly, GPT-3 performs poorly at answering straightforward questions about simple synthetic statutes. By also posing the same questions when the synthetic statutes are written in sentence form, we find that some of GPT-3\u2019s poor performance results from difficulty in parsing the typical structure of statutes, containing subsections and paragraphs.</p>"},{"location":"Ressources/Papiers%20de%20recherche/#similar-case-prediction","title":"Similar Case Prediction","text":""},{"location":"Ressources/Papiers%20de%20recherche/#complex-labelling-and-similarity-prediction-in-legal-texts-automatic-analysis-of-frances-court-of-cassation-rulings","title":"Complex Labelling and Similarity Prediction in Legal Texts: Automatic Analysis of France\u2019s Court of Cassation Rulings","text":"<p>https://hal.inria.fr/hal-03663110/file/LREC_2022___CCass_Inria-camera-ready.pdf https://github.com/rbawden/Similarity-cour-de-cassation Abstract Detecting divergences in the applications of the law (where the same legal text is applied differently by two rulings) is an important task. It is the mission of the French Cour de Cassation. The first step in the detection of divergences is to detect similar cases, which is currently done manually by experts. They rely on summarised versions of the rulings (syntheses and keyword sequences), which are currently produced manually and are not available for all rulings. There is also a high degree of variability in the keyword choices and the level of granularity used. In this article, we therefore aim to provide automatic tools to facilitate the search for similar rulings. We do this by (i) providing automatic keyword sequence generation models, which can be used to improve the coverage of the analysis, and (ii) providing measures of similarity based on the available texts and augmented with predicted keyword sequences. Our experiments show that the predictions improve correlations of automatically obtained similarities against our specially colelcted human judgments of similarity</p>"},{"location":"Ressources/Papiers%20de%20recherche/#classification-ner","title":"Classification / NER","text":""},{"location":"Ressources/Papiers%20de%20recherche/#pyeurovoc-a-tool-for-multilingual-legal-document-classification-with-eurovoc-descriptors","title":"PyEuroVoc: A Tool for Multilingual Legal Document Classification with EuroVoc Descriptors","text":"<p>https://arxiv.org/pdf/2108.01139.pdf Abstract EuroVoc is a multilingual thesaurus that was built for organizing the legislative documentary of the European Union institutions. It contains thousands of categories at different levels of specificity and its descriptors are targeted by legal texts in almost thirty languages. In this work we propose a unified framework for EuroVoc classification on 22 languages by finetuning modern Transformer-based pretrained language models. We study extensively the performance of our trained models and show that they significantly improve the results obtained by a similar tool - JEX - on the same dataset. The code and the fine-tuned models were open sourced, together with a programmatic interface that eases the process of loading the weights of a trained model and of classifying a new document.</p>"},{"location":"Ressources/Papiers%20de%20recherche/#large-scale-multi-label-text-classification-on-eu-legislation","title":"Large-Scale Multi-Label Text Classification on EU Legislation","text":"<p>https://arxiv.org/pdf/1906.02192.pdf Abstract  We consider Large-Scale Multi-Label Text Classification (LMTC) in the legal domain. We release a new dataset of 57k legislative documents from EUR-LEX, annotated with \u223c4.3k EUROVOC labels, which is suitable for LMTC, few- and zero-shot learning. Experimenting with several neural classifiers, we show that BIGRUs with label-wise attention perform better than other current state of the art methods. Domain-specific WORD2VEC and context-sensitive ELMO embeddings further improve performance. We also find that considering only particular zones of the documents is sufficient. This allows us to bypass BERT\u2019s maximum text length limit and finetune BERT, obtaining the best results in all but zero-shot learning cases.</p>"},{"location":"Ressources/Papiers%20de%20recherche/#the-unreasonable-effectiveness-of-the-baseline-discussing-svms-in-legal-text-classification","title":"The Unreasonable Effectiveness of the Baseline: Discussing SVMs in Legal Text Classification","text":"<p>https://arxiv.org/pdf/2109.07234.pdf Abstract We aim to highlight an interesting trend to contribute to the ongoing debate around advances within legal Natural Language Processing. Recently, the focus for most legal text classification tasks has shifted towards large pre-trained deep learning models such as BERT. In this paper, we show that a more traditional approach based on Support Vector Machine classifiers reaches surprisingly competitive performance with BERT-based models on the classification tasks in the LexGLUE benchmark. We also highlight that error reduction obtained by using specialised BERT-based models over baselines is noticeably smaller in the legal domain when compared to general language tasks. We present and discuss three hypotheses as potential explanations for these results to support future discussions.</p>"},{"location":"Ressources/Papiers%20de%20recherche/#effectively-leveraging-bert-for-legal-document-classification","title":"Effectively Leveraging BERT for Legal Document Classification","text":"<p>https://aclanthology.org/2021.nllp-1.22.pdf Abstract Bidirectional Encoder Representations from Transformers (BERT) has achieved state-of-the-art performances on several text classification tasks, such as GLUE and sentiment analysis. Recent work in the legal domain started touse BERT on tasks, such as legal judgementprediction and violation prediction. A common practise in using BERT is to fine-tune apre-trained model on a target task and truncatethe input texts to the size of the BERT input (e.g. at most 512 tokens). However, due to the unique characteristics of legal documents, it is not clear how to effectively adapt BERT in the legal domain. In this work, we investigate how to deal with long documents, and how is the importance of pre-training on documents from the same domain as the target task. We conduct experiments on the two recent datasets: ECHR Violation Dataset and the Overruling Task Dataset, which are multi-label and binary classification tasks, respectively. Importantly, on average the number of tokens in a document from the ECHR Violation Dataset is more than 1,600. While the documents in the Overruling Task Dataset are shorter (the maximum number of tokens is 204). We thoroughly compare several techniques for adapting BERT on long documents and compare different models pretrained on the legal and other domains. Our experimental results show that we need to explicitly adapt BERT to handle long documents, as the truncation leads to less effective performance. We also found that pre-training on the documents that are similar to the target task would result in more effective performance on several scenario.</p>"},{"location":"Ressources/Papiers%20de%20recherche/#predicting-the-law-area-and-decisions-of-french-supreme-court-cases","title":"Predicting the Law Area and Decisions of French Supreme Court Cases","text":"<p>https://www.acl-bg.org/proceedings/2017/RANLP%202017/pdf/RANLP092.pdf Abstract In this paper, we investigate the application of text classification methods to predict the law area and the decision of cases judged by the French Supreme Court. We also investigate the influence of the time period in which a ruling was made over the textual form of the case description and the extent to which it is necessary to mask the judge\u2019s motivation for a ruling to emulate a real-world test scenario. We report results of 96% f1 score in predicting a case ruling, 90% f1 score in predicting the law area of a case, and 75.9% f1 score in estimating the time span when a ruling has been issued using a linear Support Vector Machine (SVM) classifier trained on lexicalfeatures.</p>"},{"location":"Ressources/Papiers%20de%20recherche/#extracting-proceedings-information-and-legal-references-from-court-decisions-with-machine-learning","title":"Extracting Proceedings Information and Legal References from Court Decisions with Machine-Learning","text":"<p>https://papers.ssrn.com/sol3/Delivery.cfm/SSRN_ID3921634_code3536982.pdf?abstractid=3919849&amp;mirid=1 Abstract This research examines the level of quality of information extracted from court decisions thanks to supervised machine-learning. The perimeter of the experience encompasses French civil decisions of all three jurisdictional degrees. It covers proceedings data, such as judicial dates and jurisdictions, and legal citations. The experience involves multi-label named-entity recognition (NER) and compares different algorithms : CRF, Spacy, Flair and DeLFT. An overall quality score of 87.5% has been reached with Flair and a large number of annotations unevenly distributed among 27 labels. Individual legal references are extracted with a score of 90% through a specific two-step training combining CRF and Flair. The paper also proposes a methodology based on a model mix to save annotation time. </p>"},{"location":"Ressources/Papiers%20de%20recherche/#information-retrieval","title":"Information retrieval","text":""},{"location":"Ressources/Papiers%20de%20recherche/#a-statutory-article-retrieval-dataset-in-french","title":"A Statutory Article Retrieval Dataset in French","text":"<p>https://arxiv.org/pdf/2108.11792.pdf</p> <p>Abstract Statutory article retrieval is the task of automatically retrieving law articles relevant to a legal question. While recent advances in natural language processing have sparked considerable interest in many legal tasks, statutory article retrieval remains primarily untouched due to the scarcity of large-scale and highquality annotated datasets. To address this bottleneck, we introduce the Belgian Statutory Article Retrieval Dataset (BSARD), which consists of 1,100+ French native legal questions labeled by experienced jurists with relevant articles from a corpus of 22,600+ Belgian law articles. Using BSARD, we benchmark several state-of-the-art retrieval approaches, including lexical and dense architectures, both in zero-shot and supervised setups. We find that fine-tuned dense retrieval models significantly outperform other systems. Our best performing baseline achieves 74.8% R@100, which is promising for the feasibility of the task and indicates there is still room for improvement. By the specificity of the domain and addressed task, BSARD presents a unique challenge problem for future research on legal information retrieval. Our dataset and source code are publicly available</p>"},{"location":"Ressources/Papiers%20de%20recherche/#dataset-benchmark","title":"Dataset /Benchmark","text":""},{"location":"Ressources/Papiers%20de%20recherche/#lexglue-a-benchmark-dataset-for","title":"LexGLUE: A Benchmark Dataset for","text":"<p>Legal Language Understanding in English https://arxiv.org/pdf/2110.00976.pdf Abstract Laws and their interpretations, legal arguments and agreements are typically expressed in writing, leading to the production of vast corpora of legal text. Their analysis, which is at the center of legal practice, becomes increasingly elaborate as these collections grow in size. Natural language understanding (NLU) technologies can be a valuable tool to support legal practitioners in these endeavors. Their usefulness, however, largely depends on whether current state-of-the-art models can generalize across various tasks in the legal domain. To answer this currently open question, we introduce the Legal General Language Understanding Evaluation (LexGLUE) benchmark, a collection of datasets for evaluating model performance across a diverse set of legal NLU tasks in a standardized way. We also provide an evaluation and analysis of several generic and legal-oriented models demonstrating that the latter consistently offer performance improvements across multiple tasks.</p>"},{"location":"Ressources/Papiers%20de%20recherche/#fairlex-a-multilingual-benchmark-for-evaluating-fairness-in-legal-text-processing","title":"FairLex: A Multilingual Benchmark for Evaluating Fairness in Legal Text Processing","text":"<p>https://arxiv.org/pdf/2203.07228.pdf Abstract We present a benchmark suite of four datasets for evaluating the fairness of pre-trained language models and the techniques used to fine-tune them for downstream tasks. Our benchmarks cover four jurisdictions (European Council, USA, Switzerland, and China), five languages (English, German, French, Italian and Chinese) and fairness across five attributes (gender, age, region, language, and legal area). In our experiments, we evaluate pretrained language models using several grouprobust fine-tuning techniques and show that performance group disparities are vibrant in many cases, while none of these techniques guarantee fairness, nor consistently mitigate group disparities. Furthermore, we provide a quantitative and qualitative analysis of our results, highlighting open challenges in the development of robustness methods in legal NLP.</p>"},{"location":"Ressources/Papiers%20de%20recherche/#cuad-an-expert-annotated-nlp-dataset-for-legal-contract-review","title":"CUAD: An Expert-Annotated NLP Dataset for\u00a0 Legal Contract Review","text":"<p>https://arxiv.org/pdf/2103.06268.pdf Abstract Many specialized domains remain untouched by deep learning, as large labeled datasets require expensive expert annotators. We address this bottleneck within the\u00a0legal domain by introducing the Contract Understanding Atticus Dataset (CUAD), a new dataset for\u00a0legal contract review. CUAD was created with dozens of\u00a0legal experts from The Atticus Project and consists of over 13,000 annotations. The task is to highlight salient portions of a contract that are important for a human to review. We find that Transformer models have nascent performance, but that this performance is strongly influenced by model design and training dataset size. Despite these promising results, there is still substantial room for improvement. As one of the only large, specialized NLP benchmarks annotated by experts, CUAD can serve as a challenging research benchmark for the broader NLP community.</p>"},{"location":"Ressources/Papiers%20de%20recherche/#justice-predictive-jurimetrie","title":"Justice pr\u00e9dictive / Jurim\u00e9trie","text":""},{"location":"Ressources/Papiers%20de%20recherche/#swiss-judgment-prediction-a-multilingual-legal","title":"Swiss-Judgment-Prediction: A Multilingual Legal","text":"<p>Judgment Prediction Benchmark https://arxiv.org/pdf/2110.00806.pdf Abstract In many jurisdictions, the excessive workload of courts leads to high delays. Suitable predictive AI models can assist legal professionals in their work, and thus enhance and speed up the process. So far, Legal Judgment Prediction (LJP) datasets have been released in English, French, and Chinese. We publicly release a multilingual (German, French, and Italian), diachronic (2000-2020) corpus of 85K cases from the Federal Supreme Court of Switzerland (FSCS). We evaluate state-of-the-art BERT-based methods including two variants of BERT that overcome the BERT input (text) length limitation (up to 512 tokens). Hierarchical BERT has the best performance (approx. 68-70% Macro-F1-Score in German and French). Furthermore, we study how several factors (canton of origin, year of publication, text length, legal area) affect performance. We release both the benchmark dataset and our code to accelerate future research and ensure reproducibility</p>"},{"location":"Ressources/Papiers%20de%20recherche/#dependency-learning-for-legal-judgment","title":"Dependency Learning for Legal Judgment","text":"<p>Prediction with a Unified Text-to-Text Transformer https://arxiv.org/pdf/2112.06370.pdf Abstract Given the fact of a case, Legal Judgment Prediction (LJP) involves a series of sub-tasks such as predicting violated law articles, charges and term of penalty. We propose leveraging a unified text-to-text Transformer for LJP, where the dependencies among sub-tasks can be naturally established within the auto-regressive decoder. Compared with previous works, it has three advantages: (1) it fits in the pretraining pattern of masked language models, and thereby can benefit from the semantic prompts of each sub-task rather than treating them as atomic labels, (2) it utilizes a single unified architecture, enabling full parameter sharing across all sub-tasks, and (3) it can incorporate both classification and generative sub-tasks. We show that this unified transformer, albeit pretrained on general-domain text, outperforms pretrained models tailored specifically for the legal domain. Through an extensive set of experiments, we find that the best order to capture dependencies is different from human intuitions, and the most reasonable logical order for humans can be sub-optimal for the model. We further include two more auxiliary tasks: court view generation and article content prediction, showing they can not only improve the prediction accuracy, but also provide interpretable explanations for model outputs even when an error is made. With the best configuration, our model outperforms both previous SOTA and a single-tasked version of the unified transformer by a large margin. Code and dataset are available at https://github.com/oli-yun/Dependency-LJP.</p>"},{"location":"Ressources/Papiers%20de%20recherche/#deconfounding-legal-judgment-prediction-for-european-court-of-human-rights-cases-towards-better-alignment-with-experts","title":"Deconfounding Legal Judgment Prediction for European Court of Human Rights Cases Towards Better Alignment with Experts","text":"<p>https://arxiv.org/pdf/2210.13836.pdf Abstract This work demonstrates that Legal Judgement Prediction systems without expert-informed adjustments can be vulnerable to shallow, distracting surface signals that arise from corpus construction, case distribution, and confounding factors. To mitigate this, we use domain expertise to strategically identify statistically predictive but legally irrelevant information. We adopt adversarial training to prevent the system from relying on it. We evaluate our deconfounded models by employing interpretability techniques and comparing to expert annotations. Quantitative experiments and qualitative analysis show that our deconfounded model consistently aligns better with expert rationales than baselines trained for prediction only. We further contribute a set of reference expert annotations to the validation and testing partitions of an existing benchmark dataset of European Court of Human Rights cases.</p>"}]}